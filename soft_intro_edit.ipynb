{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438abb3-7f9a-4c4c-92a9-e64527ebcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import models.models as models\n",
    "import utils.confusion as confusion\n",
    "import utils.my_trainer as trainer\n",
    "import utils.train_result as train_result\n",
    "from datasets.dataset import load_data\n",
    "from utils.data_class import BrainDataset\n",
    "\n",
    "# import os.path as osp\n",
    "import torchio as tio\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from torchio.transforms.augmentation.intensity.random_bias_field import RandomBiasField\n",
    "from torchio.transforms.augmentation.intensity.random_noise import RandomNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8d10d4-2eae-4c48-8701-0b5a17688954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True #この行をFalseにすると再現性はとれるが、速度が落ちる\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return\n",
    "fix_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ac9304-9a2d-4025-9769-a2c150f00c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\"CN\": 0, \"AD\": 1}\n",
    "SEED_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4e817a-4014-45db-993d-f68de351b799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "data = load_data(kinds=[\"ADNI2\"], classes=[\"CN\"], unique=False, blacklist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20bcf3d-6f50-4ad1-8609-a1d09de8822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 324.91it/s]\n"
     ]
    }
   ],
   "source": [
    "pids = []\n",
    "voxels = np.zeros((len(data), 80, 96, 80))\n",
    "labels = np.zeros(len(data))\n",
    "for i in tqdm(range(len(data))):\n",
    "    pids.append(data[i][\"pid\"])\n",
    "    voxels[i] = data[i][\"voxel\"]\n",
    "    labels[i] = CLASS_MAP[data[i][\"label\"]]\n",
    "pids = np.array(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfe1bef-13a2-4acf-9cc9-14bfcb91136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import CLASS_MAP\n",
    "from torch.utils.data import Dataset\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, voxels, labels, transform=None):\n",
    "        self.voxels = voxels\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.voxels)\n",
    "    def __getitem__(self, index):\n",
    "        voxel = self.voxels[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            voxel = self.transform(voxel, self.phase)\n",
    "        voxel = self._preprocess(voxel)\n",
    "        return voxel, label\n",
    "    def _preprocess(self, voxel):\n",
    "        cut_range = 4\n",
    "        voxel = np.clip(voxel, 0, cut_range * np.std(voxel))\n",
    "        voxel = normalize(voxel, np.min(voxel), np.max(voxel))\n",
    "        voxel = voxel[np.newaxis, ]\n",
    "        return voxel.astype('f')\n",
    "    def __call__(self, index):\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    \n",
    "def normalize(voxel: np.ndarray, floor: int, ceil: int) -> np.ndarray:\n",
    "    return (voxel - floor) / (ceil - floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51db581-d3bc-46d7-941f-43f461c2f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "tid, vid = list(gss.split(voxels, groups=pids))[0]\n",
    "train_voxels = voxels[tid]\n",
    "val_voxels = voxels[vid]\n",
    "train_labels = labels[tid]\n",
    "val_labels = labels[vid]\n",
    "\n",
    "train_dataset = BrainDataset(train_voxels, train_labels)\n",
    "val_dataset = BrainDataset(val_voxels, val_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8963cce0-f8c3-4427-ac93-b50696987aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2 ** 32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "# g = torch.Generator()\n",
    "# g.manual_seed(0)\n",
    "\n",
    "# num_workers = 2\n",
    "# batch_size = 16\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=seed_worker, generator=g)\n",
    "# val_dataloader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16bbef25-4291-4b17-8bae-f9072150bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_kl(logvar, mu, mu_o=0.0, logvar_o=0.0, reduce='sum'):\n",
    "    if not isinstance(mu_o, torch.Tensor):\n",
    "        mu_o = torch.tensor(mu_o).to(mu.device)\n",
    "    if not isinstance(logvar_o, torch.Tensor):\n",
    "        logvar_o = torch.tensor(logvar_o).to(mu.device)\n",
    "    kl = -0.5 * (1 + logvar - logvar_o - logvar.exp() / torch.exp(logvar_o) - (mu - mu_o).pow(2) / torch.exp(\n",
    "        logvar_o)).sum(1)\n",
    "    if reduce == 'sum':\n",
    "        kl = torch.sum(kl)\n",
    "    elif reduce == 'mean':\n",
    "        kl = torch.mean(kl)\n",
    "    return kl\n",
    "\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    \"\"\"\n",
    "    This function applies the reparameterization trick:\n",
    "    z = mu(X) + sigma(X)^0.5 * epsilon, where epsilon ~ N(0,I)\n",
    "    :param mu: mean of x\n",
    "    :param logvar: log variaance of x\n",
    "    :return z: the sampled latent variable\n",
    "    \"\"\"\n",
    "    device = mu.device\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std).to(device)\n",
    "    return mu + eps * std\n",
    "\n",
    "\n",
    "def calc_reconstruction_loss(x, recon_x, loss_type='mse', reduction='mean'):\n",
    "    x = x.view(x.size(0), -1)\n",
    "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    \n",
    "    recon_error = F.mse_loss(recon_x, x, reduction='none')\n",
    "    recon_error = recon_error.sum(1)\n",
    "    recon_error = recon_error.mean()\n",
    "    return recon_error\n",
    "\n",
    "\n",
    "def load_model(model, pretrained, device):\n",
    "    weights = torch.load(pretrained, map_location=device)\n",
    "    model.load_state_dict(weights['model'], strict=False)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, epoch, iteration, prefix=\"\"):\n",
    "    model_out_path = \"./saves/\" + prefix + \"model_epoch_{}_iter_{}.pth\".format(epoch, iteration)\n",
    "    state = {\"epoch\": epoch, \"model\": model.state_dict()}\n",
    "    if not os.path.exists(\"./saves/\"):\n",
    "        os.makedirs(\"./saves/\")\n",
    "\n",
    "    torch.save(state, model_out_path)\n",
    "\n",
    "    print(\"model checkpoint saved @ {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb03b5a-217e-4434-89ab-197b3b0f4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BuildingBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(BuildingBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool3d(kernel_size=stride),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "class UpsampleBuildingkBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(UpsampleBuildingkBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, in_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=stride),\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.block_setting = block_setting\n",
    "        self.in_ch = in_ch\n",
    "        last = 1\n",
    "        blocks = [nn.Sequential(\n",
    "            nn.Conv3d(1, in_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )]\n",
    "        for line in self.block_setting:\n",
    "            c, n, s = line[0], line[1], line[2]\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(nn.Sequential(BuildingBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        self.inner_ch = in_ch\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.conv = nn.Conv3d(in_ch, last, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.blocks(x)\n",
    "        return self.conv(h)\n",
    "\n",
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, encoder: ResNetEncoder, blocks=None):\n",
    "        super(ResNetDecoder, self).__init__()\n",
    "        last = encoder.block_setting[-1][0]\n",
    "        if blocks is None:\n",
    "            blocks = [nn.Sequential(\n",
    "                nn.Conv3d(1, last, 1, 1, bias=True),\n",
    "                nn.BatchNorm3d(last),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )]\n",
    "        in_ch = last\n",
    "        for i in range(len(encoder.block_setting)):\n",
    "            if i == len(encoder.block_setting) - 1:\n",
    "                nc = encoder.in_ch\n",
    "            else:\n",
    "                nc = encoder.block_setting[::-1][i + 1][0]\n",
    "            c, n, s = encoder.block_setting[::-1][i]\n",
    "            for j in range(n):\n",
    "                stride = s if j == n - 1 else 1\n",
    "                c = nc if j == n - 1 else c\n",
    "                blocks.append(nn.Sequential(UpsampleBuildingkBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        blocks.append(nn.Sequential(\n",
    "            nn.Conv3d(in_ch, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.blocks(x)\n",
    "\n",
    "\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseEncoder, self).__init__()\n",
    "class BaseDecoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseDecoder, self).__init__()\n",
    "\n",
    "class BaseCAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseCAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "    def decode(self, z):\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        out = self.decode(z)\n",
    "        return out, z\n",
    "\n",
    "class BaseVAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseVAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "    def decode(self, vec):\n",
    "        out = self.decoder(vec)\n",
    "        return out\n",
    "    def reparameterize(self, mu, logvar) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        vec = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(vec)\n",
    "        return x_hat, vec, mu, logvar\n",
    "\n",
    "\n",
    "class ResNetCAE(BaseCAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetCAE, self).__init__()\n",
    "        self.encoder = ResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class VAEResNetEncoder(ResNetEncoder):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(VAEResNetEncoder, self).__init__(in_ch, block_setting)\n",
    "        self.mu = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "        self.var = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h = self.blocks(x)\n",
    "        mu = self.mu(h)\n",
    "        var = self.var(h)\n",
    "        return mu, var\n",
    "\n",
    "\n",
    "class ResNetVAE(BaseVAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetVAE, self).__init__()\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "\n",
    "    def reparamenterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparamenterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return x_re, mu, logvar\n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e869defe-1f68-4454-80ab-3003dfcc782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftIntroVAE(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting, zdim=150, conditional=False):\n",
    "        super(SoftIntroVAE, self).__init__()\n",
    "        self.zdim = zdim\n",
    "        self.conditional = conditional\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return mu, logvar, z, x_re\n",
    "    \n",
    "#     ↑ここの forward では  RETURN {{ mu, logvar, z, y }}を返したい (soft-intro-vae-tutorial-codeでは)    \n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "            \n",
    "    def sample(self, z, y_cond=None):\n",
    "        # x.view(-1, 2) \n",
    "        z = z.view(32, 1, 5, 6, 5)# batchsize, channel, 5×6×5 (150)\n",
    "        y = self.decode(z, y_cond=y_cond)\n",
    "        return y\n",
    "\n",
    "    def sample_with_noise(self, num_samples=1, device=torch.device(\"cpu\"), y_cond=None):\n",
    "        z = torch.randn(num_samples, self.z_dim).to(device)\n",
    "        return self.decode(z, y_cond=y_cond)\n",
    "\n",
    "    def encode(self, x, o_cond=None):\n",
    "        # if self.conditional and o_cond is not None:\n",
    "        #     mu, logvar = self.encoder(x, o_cond=o_cond) # VAEResNetENcoder ⇒　return  mu, logvar\n",
    "        # else:\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z, y_cond=None):\n",
    "        # if self.conditional and y_cond is not None:\n",
    "        #     y = self.decoder(z, y_cond=y_cond)\n",
    "        # else:\n",
    "        y = self.decoder(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c360a2c0-a3f8-496a-9867-be9fa9f476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=16, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                           num_epochs=250, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                           beta_kl=1.0, beta_rec=1.0, beta_neg=1.0, test_iter=1000, seed=-1, pretrained=None,\n",
    "                           device=torch.device(\"cpu\"), num_row=8, gamma_r=1e-8):\n",
    "    if seed != -1:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        print(\"random seed: \", seed)\n",
    "\n",
    "    \n",
    "    model = SoftIntroVAE(12, [ [12,1,2],[24,1,2],[32,2,2],[48,2,2] ], conditional=False)\n",
    "    #model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "    model.to(device)\n",
    "    # もしpretrainedが存在しているのならば model param load\n",
    "    if pretrained is not None: \n",
    "        load_model(model, pretrained, device)\n",
    "    print(model)\n",
    "\n",
    "    optimizer_e = optim.Adam(model.encoder.parameters(), lr=lr_e)\n",
    "    optimizer_d = optim.Adam(model.decoder.parameters(), lr=lr_d)\n",
    "\n",
    "    e_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_e, milestones=(350,), gamma=0.1)\n",
    "    d_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=(350,), gamma=0.1)\n",
    "\n",
    "    scale = 1 / (80 * 96 * 80)  # normalizing constant, 's' in the paper  desu\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
    "#   train_data_loader = load_data(kinds=[\"ADNI2\",\"ADNI2-2\"], classes=[\"CN\", \"AD\"], unique=False, blacklist=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    cur_iter = 0\n",
    "    kls_real = []\n",
    "    kls_fake = []\n",
    "    kls_rec = []\n",
    "    rec_errs = []\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        diff_kls = []\n",
    "        # save models\n",
    "        if epoch % save_interval == 0 and epoch > 0:\n",
    "            save_epoch = (epoch // save_interval) * save_interval\n",
    "            prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "            save_checkpoint(model, save_epoch, cur_iter, prefix)\n",
    "\n",
    "        model.train()\n",
    "        batch_kls_real = []\n",
    "        batch_kls_fake = []\n",
    "        batch_kls_rec = []\n",
    "        batch_rec_errs = []\n",
    "\n",
    "#        for iteration, batch in enumerate(train_data_loader, 0):\n",
    "        for iteration, (batch, labels) in enumerate(train_data_loader, 0):# iterationには 自動で割り振られたindex番号が適用される\n",
    "#        for batch, labels in train_data_loader:# iterationには 自動で割り振られたindex番号が適用される\n",
    "        # enmuerate の第２引数はindexの開始番号の指定\n",
    "        # --------------train------------\n",
    "            b_size = batch.size(0)\n",
    "\n",
    "            noise_batch = torch.randn(size=(b_size, 1, 5, 6, 5)).to(device)\n",
    "            real_batch = batch.to(device)\n",
    "\n",
    "            # =========== Update E ================\n",
    "        #   fake = model.sample(noise_batch)\n",
    "            fake = model.decode(noise_batch)\n",
    "\n",
    "            real_mu, real_logvar = model.encode(real_batch)\n",
    "            z = model.reparameterize(real_mu, real_logvar)\n",
    "            rec = model.decode(z)\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            lossE_real_kl = calc_kl(real_logvar, real_mu, reduce=\"mean\")\n",
    "            # {{ mu,    logvar,    z   ,    y }}を返す\n",
    "            rec_mu, rec_logvar, z_rec, rec_rec     = model( rec.detach())\n",
    "            fake_mu, fake_logvar, z_fake, rec_fake = model(fake.detach())\n",
    "\n",
    "            fake_kl_e = calc_kl(fake_logvar, fake_mu, reduce=\"none\")\n",
    "            rec_kl_e = calc_kl(rec_logvar, rec_mu, reduce=\"none\")\n",
    "            \n",
    "            # print(\"fake：\")\n",
    "            # print( fake.size() )\n",
    "            # print(\"rec_fake：\")\n",
    "            # print( rec_fake.size() )            \n",
    "\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake, rec_fake, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec, rec_rec, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            # loss fake rec がおかしい？\n",
    "            # print(\"loss_fake_rec：\")\n",
    "            # print( loss_fake_rec )\n",
    "            # print(\" fake_kl_e：\" )\n",
    "            # print(fake_kl_e)\n",
    "\n",
    "            exp_elbo_fake = (-2 * scale * (beta_rec * loss_fake_rec + beta_neg * fake_kl_e)).exp().mean()\n",
    "            exp_elbo_rec = (-2 * scale * (beta_rec * loss_rec_rec + beta_neg * rec_kl_e)).exp().mean()\n",
    "            # total loss\n",
    "            lossE = scale * (beta_rec * loss_rec + beta_kl * lossE_real_kl) + 0.25 * (exp_elbo_fake + exp_elbo_rec)\n",
    "            # backprop\n",
    "            optimizer_e.zero_grad()\n",
    "            lossE.backward()\n",
    "            optimizer_e.step()\n",
    "       #     print(\"finish updateE\")\n",
    "            # ========= Update D ==================\n",
    "            for param in model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.decoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            fake = model.decode(noise_batch)# \n",
    "            rec = model.decode(z.detach())\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec.detach(),loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_mu, rec_logvar = model.encode(rec)\n",
    "            z_rec = reparameterize(rec_mu, rec_logvar)\n",
    "\n",
    "            fake_mu, fake_logvar = model.encode(fake)\n",
    "            z_fake = reparameterize(fake_mu, fake_logvar)\n",
    "\n",
    "            # rec_rec = model.decode(z_rec.detach())\n",
    "            # rec_fake = model.decode(z_fake.detach())\n",
    "            rec_rec = model.decode(z_rec)\n",
    "            rec_fake = model.decode(z_fake)\n",
    "\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec.detach(), rec_rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake.detach(), rec_fake, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_kl = calc_kl(rec_logvar, rec_mu, reduce=\"mean\")\n",
    "            fake_kl = calc_kl(fake_logvar, fake_mu, reduce=\"mean\")\n",
    "\n",
    "            lossD = scale * (loss_rec * beta_rec + (rec_kl + fake_kl) * 0.5 * beta_kl + \\\n",
    "                                         gamma_r * 0.5 * beta_rec * (loss_rec_rec + loss_fake_rec))\n",
    "\n",
    "            optimizer_d.zero_grad()\n",
    "            lossD.backward()\n",
    "            optimizer_d.step()\n",
    "    #        print(\"finish updateD\")\n",
    "\n",
    "            if torch.isnan(lossD) or torch.isnan(lossE):\n",
    "                raise SystemError\n",
    "\n",
    "            # statistics for plotting later\n",
    "            diff_kls.append(-lossE_real_kl.data.cpu().item() + fake_kl.data.cpu().item())\n",
    "            batch_kls_real.append(lossE_real_kl.data.cpu().item())\n",
    "            batch_kls_fake.append(fake_kl.cpu().item())\n",
    "            batch_kls_rec.append(rec_kl.data.cpu().item())\n",
    "            batch_rec_errs.append(loss_rec.data.cpu().item())\n",
    "\n",
    "            #if cur_iter % test_iter == 0:\n",
    "        info = \"\\nEpoch[{}]({}/{}): time: {:4.4f}: \".format(epoch, iteration, len(train_data_loader), time.time() - start_time)\n",
    "        info += 'Rec: {:.4f}, '.format(loss_rec.data.cpu())\n",
    "        info += 'Kl_E: {:.4f}, expELBO_R: {:.4e}, expELBO_F: {:.4e}, '.format(lossE_real_kl.data.cpu(),\n",
    "                                                                        exp_elbo_rec.data.cpu(),\n",
    "                                                                        exp_elbo_fake.cpu())\n",
    "        info += 'Kl_F: {:.4f}, KL_R: {:.4f}'.format(rec_kl.data.cpu(), fake_kl.data.cpu())\n",
    "        info += ' DIFF_Kl_F: {:.4f}'.format(-lossE_real_kl.data.cpu() + fake_kl.data.cpu())\n",
    "        print(info)\n",
    "\n",
    "        _, _, _, rec_det = model(real_batch)\n",
    "        max_imgs = min(batch.size(0), 16)\n",
    "        # vutils.save_image(\n",
    "        #         torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "        #         '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)                 \n",
    "        #cur_iter += 1\n",
    "    e_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "\n",
    "    if epoch > num_vae - 1:\n",
    "        kls_real.append(np.mean(batch_kls_real))\n",
    "        kls_fake.append(np.mean(batch_kls_fake))\n",
    "        kls_rec.append(np.mean(batch_kls_rec))\n",
    "        rec_errs.append(np.mean(batch_rec_errs))\n",
    "\n",
    "#     if epoch == num_epochs - 1:\n",
    "#         with torch.no_grad():\n",
    "#             _, _, _, rec_det = model(real_batch)\n",
    "#             noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
    "#             fake = model.sample(noise_batch)\n",
    "#             max_imgs = min(batch.size(0), 16)\n",
    "#             vutils.save_image(\n",
    "#                     torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "#                     '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)\n",
    "\n",
    "#         # plot graphs\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(1, 1, 1)\n",
    "#         ax.plot(np.arange(len(kls_real)), kls_real, label=\"kl_real\")\n",
    "#         ax.plot(np.arange(len(kls_fake)), kls_fake, label=\"kl_fake\")\n",
    "#         ax.plot(np.arange(len(kls_rec)), kls_rec, label=\"kl_rec\")\n",
    "#         ax.plot(np.arange(len(rec_errs)), rec_errs, label=\"rec_err\")\n",
    "#         ax.set_ylim([0, 200])\n",
    "#         ax.legend()\n",
    "#         plt.savefig('./soft_intro_vae_train_graphs.jpg')\n",
    "#         # save models\n",
    "#         prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "#         save_checkpoint(model, epoch, cur_iter, prefix)\n",
    "#         plt.show()\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a833464-fbaf-4e16-aff2-54f0f737dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "SoftIntroVAE(\n",
      "  (encoder): VAEResNetEncoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(24, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    (mu): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    (var): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (decoder): ResNetDecoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv3d(1, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=1.0, mode=nearest)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=1.0, mode=nearest)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(32, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Conv3d(12, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Epoch[0](7/8): time: 26.0277: Rec: 99954.3750, Kl_E: 17.7774, expELBO_R: 7.5458e-01, expELBO_F: 6.8520e-01, Kl_F: 4071.6089, KL_R: 297.5927 DIFF_Kl_F: 279.8153\n",
      "\n",
      "Epoch[1](7/8): time: 48.8421: Rec: 89152.5703, Kl_E: 31.2676, expELBO_R: 6.9788e-01, expELBO_F: 6.5675e-01, Kl_F: 922.0190, KL_R: 266.4987 DIFF_Kl_F: 235.2311\n",
      "\n",
      "Epoch[2](7/8): time: 70.5037: Rec: 109726.8125, Kl_E: 49.1439, expELBO_R: 7.0893e-01, expELBO_F: 6.5430e-01, Kl_F: 2720.6562, KL_R: 578.9208 DIFF_Kl_F: 529.7769\n",
      "\n",
      "Epoch[3](7/8): time: 91.9945: Rec: 92285.8281, Kl_E: 37.3015, expELBO_R: 8.0645e-01, expELBO_F: 7.3708e-01, Kl_F: 27200.1387, KL_R: 528.9653 DIFF_Kl_F: 491.6638\n",
      "\n",
      "Epoch[4](7/8): time: 113.0469: Rec: 101609.2969, Kl_E: 95.0392, expELBO_R: 8.4694e-01, expELBO_F: 7.7938e-01, Kl_F: 10888.7207, KL_R: 6234.1602 DIFF_Kl_F: 6139.1211\n",
      "\n",
      "Epoch[5](7/8): time: 134.5712: Rec: 107055.3672, Kl_E: 71.5517, expELBO_R: 7.6366e-01, expELBO_F: 6.9003e-01, Kl_F: 4748.0610, KL_R: 273.7138 DIFF_Kl_F: 202.1621\n",
      "\n",
      "Epoch[6](7/8): time: 155.8905: Rec: 119097.8438, Kl_E: 65.8987, expELBO_R: 8.3628e-01, expELBO_F: 7.5003e-01, Kl_F: 3365.1802, KL_R: 25183.6445 DIFF_Kl_F: 25117.7461\n",
      "\n",
      "Epoch[7](7/8): time: 177.2909: Rec: 106492.1797, Kl_E: 182.8626, expELBO_R: 7.2253e-01, expELBO_F: 7.0074e-01, Kl_F: 2295.2771, KL_R: 10356.9482 DIFF_Kl_F: 10174.0859\n",
      "\n",
      "Epoch[8](7/8): time: 198.9722: Rec: 113782.7344, Kl_E: 78.3359, expELBO_R: 7.6064e-01, expELBO_F: 6.7955e-01, Kl_F: 1050.4075, KL_R: 163095.1094 DIFF_Kl_F: 163016.7812\n",
      "\n",
      "Epoch[9](7/8): time: 220.3144: Rec: 121841.3672, Kl_E: 69.1431, expELBO_R: 8.5090e-01, expELBO_F: 7.3016e-01, Kl_F: 6183.9058, KL_R: 89575.4688 DIFF_Kl_F: 89506.3281\n",
      "\n",
      "Epoch[10](7/8): time: 241.6050: Rec: 110786.4688, Kl_E: 107.1587, expELBO_R: 7.2788e-01, expELBO_F: 7.4103e-01, Kl_F: 752.9244, KL_R: 10618.5088 DIFF_Kl_F: 10511.3496\n",
      "\n",
      "Epoch[11](7/8): time: 263.5412: Rec: 110867.5391, Kl_E: 71.2791, expELBO_R: 7.7768e-01, expELBO_F: 6.9762e-01, Kl_F: 2330.3796, KL_R: 4463.3525 DIFF_Kl_F: 4392.0732\n",
      "\n",
      "Epoch[12](7/8): time: 284.9402: Rec: 118170.2031, Kl_E: 75.8131, expELBO_R: 8.2758e-01, expELBO_F: 6.6764e-01, Kl_F: 4500.0312, KL_R: 2772.6348 DIFF_Kl_F: 2696.8218\n",
      "\n",
      "Epoch[13](7/8): time: 306.7324: Rec: 127347.3750, Kl_E: 49.6157, expELBO_R: 8.4535e-01, expELBO_F: 6.9079e-01, Kl_F: 3906.4473, KL_R: 8636.8740 DIFF_Kl_F: 8587.2588\n",
      "\n",
      "Epoch[14](7/8): time: 328.4666: Rec: 131416.7031, Kl_E: 61.2216, expELBO_R: 8.4668e-01, expELBO_F: 6.5563e-01, Kl_F: 1867.3434, KL_R: 877.4513 DIFF_Kl_F: 816.2297\n",
      "\n",
      "Epoch[15](7/8): time: 350.4591: Rec: 136989.5625, Kl_E: 594.1699, expELBO_R: 8.5710e-01, expELBO_F: 6.3970e-01, Kl_F: 1689.2030, KL_R: 808.4370 DIFF_Kl_F: 214.2671\n",
      "\n",
      "Epoch[16](7/8): time: 372.3375: Rec: 125343.0625, Kl_E: 95.6927, expELBO_R: 8.2502e-01, expELBO_F: 6.9404e-01, Kl_F: 1805.1846, KL_R: 36961.7422 DIFF_Kl_F: 36866.0508\n",
      "\n",
      "Epoch[17](7/8): time: 394.2112: Rec: 112747.6562, Kl_E: 77.0630, expELBO_R: 6.8045e-01, expELBO_F: 6.9720e-01, Kl_F: 1978.4319, KL_R: 162.9377 DIFF_Kl_F: 85.8747\n",
      "\n",
      "Epoch[18](7/8): time: 415.4355: Rec: 138355.2500, Kl_E: 60.4289, expELBO_R: 8.4784e-01, expELBO_F: 6.1530e-01, Kl_F: 1505.6511, KL_R: 3469.6206 DIFF_Kl_F: 3409.1917\n",
      "\n",
      "Epoch[19](7/8): time: 436.6617: Rec: 104669.0234, Kl_E: 36.1698, expELBO_R: 7.0191e-01, expELBO_F: 6.6075e-01, Kl_F: 4068.5317, KL_R: 1721.2500 DIFF_Kl_F: 1685.0802\n",
      "\n",
      "Epoch[20](7/8): time: 458.4971: Rec: 131991.5000, Kl_E: 86.7938, expELBO_R: 8.5292e-01, expELBO_F: 6.2479e-01, Kl_F: 1665.7678, KL_R: 203.9960 DIFF_Kl_F: 117.2022\n",
      "\n",
      "Epoch[21](7/8): time: 480.1052: Rec: 110198.5781, Kl_E: 43.9268, expELBO_R: 7.7442e-01, expELBO_F: 7.1738e-01, Kl_F: 4322.2168, KL_R: 482.6662 DIFF_Kl_F: 438.7393\n",
      "\n",
      "Epoch[22](7/8): time: 502.1481: Rec: 123585.0000, Kl_E: 84.9994, expELBO_R: 8.5188e-01, expELBO_F: 6.4593e-01, Kl_F: 2963.2476, KL_R: 3320.3394 DIFF_Kl_F: 3235.3398\n",
      "\n",
      "Epoch[23](7/8): time: 524.1197: Rec: 120185.9609, Kl_E: 42.1453, expELBO_R: 6.9250e-01, expELBO_F: 6.9106e-01, Kl_F: 2375.0276, KL_R: 7363.0625 DIFF_Kl_F: 7320.9175\n",
      "\n",
      "Epoch[24](7/8): time: 545.9794: Rec: 117398.6250, Kl_E: 145.5671, expELBO_R: 7.2963e-01, expELBO_F: 7.5248e-01, Kl_F: 1147.4607, KL_R: 5188.6001 DIFF_Kl_F: 5043.0332\n",
      "\n",
      "Epoch[25](7/8): time: 567.1218: Rec: 139509.6250, Kl_E: 106.5670, expELBO_R: 8.3541e-01, expELBO_F: 7.0839e-01, Kl_F: 2777.7922, KL_R: 6390.7930 DIFF_Kl_F: 6284.2261\n",
      "\n",
      "Epoch[26](7/8): time: 588.2870: Rec: 119601.0234, Kl_E: 56.7980, expELBO_R: 7.4924e-01, expELBO_F: 6.7544e-01, Kl_F: 1390.1879, KL_R: 930.3970 DIFF_Kl_F: 873.5990\n",
      "\n",
      "Epoch[27](7/8): time: 610.3884: Rec: 122425.0859, Kl_E: 72.9548, expELBO_R: 7.0950e-01, expELBO_F: 7.0325e-01, Kl_F: 607.9008, KL_R: 16912.4512 DIFF_Kl_F: 16839.4961\n",
      "\n",
      "Epoch[28](7/8): time: 632.2721: Rec: 145515.2812, Kl_E: 202.7523, expELBO_R: 7.7684e-01, expELBO_F: 6.4277e-01, Kl_F: 4431.7471, KL_R: 3023.1643 DIFF_Kl_F: 2820.4121\n",
      "\n",
      "Epoch[29](7/8): time: 654.2876: Rec: 144472.0156, Kl_E: 691.5509, expELBO_R: 7.9312e-01, expELBO_F: 6.1644e-01, Kl_F: 3071.7114, KL_R: 3160.9158 DIFF_Kl_F: 2469.3647\n",
      "\n",
      "Epoch[30](7/8): time: 675.4977: Rec: 146451.1719, Kl_E: 45.5884, expELBO_R: 8.1826e-01, expELBO_F: 6.1621e-01, Kl_F: 2822.3320, KL_R: 7448.6709 DIFF_Kl_F: 7403.0825\n",
      "\n",
      "Epoch[31](7/8): time: 697.6453: Rec: 133671.8438, Kl_E: 123.1408, expELBO_R: 8.1011e-01, expELBO_F: 6.6628e-01, Kl_F: 1524.0959, KL_R: 4638.4141 DIFF_Kl_F: 4515.2734\n",
      "\n",
      "Epoch[32](7/8): time: 718.9881: Rec: 108784.3125, Kl_E: 37.7422, expELBO_R: 6.4791e-01, expELBO_F: 7.6687e-01, Kl_F: 712.9372, KL_R: 548.2113 DIFF_Kl_F: 510.4691\n",
      "\n",
      "Epoch[33](7/8): time: 741.1111: Rec: 135344.6562, Kl_E: 55.7515, expELBO_R: 7.9016e-01, expELBO_F: 6.8474e-01, Kl_F: 3243.4851, KL_R: 11761.0986 DIFF_Kl_F: 11705.3467\n",
      "\n",
      "Epoch[34](7/8): time: 763.2257: Rec: 150563.2344, Kl_E: 778.3654, expELBO_R: 7.6834e-01, expELBO_F: 7.0412e-01, Kl_F: 3674.5164, KL_R: 757.9850 DIFF_Kl_F: -20.3804\n",
      "\n",
      "Epoch[35](7/8): time: 784.4035: Rec: 110806.2812, Kl_E: 54.7779, expELBO_R: 6.9294e-01, expELBO_F: 6.0209e-01, Kl_F: 2122.4983, KL_R: 3959.1501 DIFF_Kl_F: 3904.3723\n",
      "\n",
      "Epoch[36](7/8): time: 805.7402: Rec: 117153.9062, Kl_E: 62.8921, expELBO_R: 7.2782e-01, expELBO_F: 6.1205e-01, Kl_F: 1368.6661, KL_R: 14062.2920 DIFF_Kl_F: 13999.4004\n",
      "\n",
      "Epoch[37](7/8): time: 827.2853: Rec: 147085.3125, Kl_E: 59.9752, expELBO_R: 8.2209e-01, expELBO_F: 6.1922e-01, Kl_F: 1741.8624, KL_R: 6191.8901 DIFF_Kl_F: 6131.9150\n",
      "\n",
      "Epoch[38](7/8): time: 848.4652: Rec: 146385.0469, Kl_E: 63.0172, expELBO_R: 8.0366e-01, expELBO_F: 7.1538e-01, Kl_F: 2401.7219, KL_R: 2339.7080 DIFF_Kl_F: 2276.6907\n",
      "\n",
      "Epoch[39](7/8): time: 869.6608: Rec: 149126.2969, Kl_E: 314.3568, expELBO_R: 7.7723e-01, expELBO_F: 6.4194e-01, Kl_F: 2202.7097, KL_R: 857.3096 DIFF_Kl_F: 542.9528\n",
      "\n",
      "Epoch[40](7/8): time: 890.8196: Rec: 117677.3438, Kl_E: 76.4959, expELBO_R: 6.2949e-01, expELBO_F: 6.7496e-01, Kl_F: 838.1320, KL_R: 1580.9005 DIFF_Kl_F: 1504.4047\n",
      "\n",
      "Epoch[41](7/8): time: 912.7575: Rec: 135597.8750, Kl_E: 86.8447, expELBO_R: 7.4376e-01, expELBO_F: 6.0102e-01, Kl_F: 6915.3037, KL_R: 3576.4614 DIFF_Kl_F: 3489.6167\n",
      "\n",
      "Epoch[42](7/8): time: 934.0965: Rec: 150686.8750, Kl_E: 198.8929, expELBO_R: 7.7061e-01, expELBO_F: 7.1609e-01, Kl_F: 3580.4939, KL_R: 7233.8818 DIFF_Kl_F: 7034.9888\n",
      "\n",
      "Epoch[43](7/8): time: 955.3211: Rec: 133701.2031, Kl_E: 101.7487, expELBO_R: 7.5883e-01, expELBO_F: 6.1259e-01, Kl_F: 1537.7520, KL_R: 1255.8461 DIFF_Kl_F: 1154.0974\n",
      "\n",
      "Epoch[44](7/8): time: 976.6294: Rec: 122569.1250, Kl_E: 57.6526, expELBO_R: 7.5664e-01, expELBO_F: 7.7723e-01, Kl_F: 463.7357, KL_R: 561.5389 DIFF_Kl_F: 503.8864\n",
      "\n",
      "Epoch[45](7/8): time: 997.8517: Rec: 136629.5938, Kl_E: 89.4855, expELBO_R: 8.3426e-01, expELBO_F: 6.2253e-01, Kl_F: 1367.2493, KL_R: 381.9171 DIFF_Kl_F: 292.4316\n",
      "\n",
      "Epoch[46](7/8): time: 1019.5167: Rec: 121939.1484, Kl_E: 74.3434, expELBO_R: 6.7068e-01, expELBO_F: 6.4533e-01, Kl_F: 1651.1737, KL_R: 11505.5205 DIFF_Kl_F: 11431.1768\n",
      "\n",
      "Epoch[47](7/8): time: 1041.5229: Rec: 145198.0938, Kl_E: 210.9215, expELBO_R: 7.8744e-01, expELBO_F: 6.2614e-01, Kl_F: 5950.9385, KL_R: 942.9279 DIFF_Kl_F: 732.0063\n",
      "\n",
      "Epoch[48](7/8): time: 1062.7167: Rec: 131882.1562, Kl_E: 79.2803, expELBO_R: 7.6086e-01, expELBO_F: 7.3026e-01, Kl_F: 2750.7468, KL_R: 234.5835 DIFF_Kl_F: 155.3032\n",
      "\n",
      "Epoch[49](7/8): time: 1084.0951: Rec: 114238.8359, Kl_E: 59.9855, expELBO_R: 6.3615e-01, expELBO_F: 7.1755e-01, Kl_F: 3254.2996, KL_R: 200.2028 DIFF_Kl_F: 140.2172\n",
      "\n",
      "Epoch[50](7/8): time: 1105.3998: Rec: 148256.9688, Kl_E: 294.1283, expELBO_R: 7.3847e-01, expELBO_F: 6.7602e-01, Kl_F: 8193.7705, KL_R: 177.4796 DIFF_Kl_F: -116.6488\n",
      "\n",
      "Epoch[51](7/8): time: 1126.6855: Rec: 135516.2031, Kl_E: 167.7635, expELBO_R: 8.0844e-01, expELBO_F: 5.6746e-01, Kl_F: 5731.2168, KL_R: 3114.8521 DIFF_Kl_F: 2947.0886\n",
      "\n",
      "Epoch[52](7/8): time: 1147.9821: Rec: 136027.9219, Kl_E: 92.8421, expELBO_R: 8.2678e-01, expELBO_F: 7.1156e-01, Kl_F: 5921.1221, KL_R: 3338.0869 DIFF_Kl_F: 3245.2449\n",
      "\n",
      "Epoch[53](7/8): time: 1169.0932: Rec: 123452.0234, Kl_E: 156.6440, expELBO_R: 7.0616e-01, expELBO_F: 6.1836e-01, Kl_F: 847.9263, KL_R: 458.7142 DIFF_Kl_F: 302.0702\n",
      "\n",
      "Epoch[54](7/8): time: 1191.0808: Rec: 141047.5938, Kl_E: 56.9699, expELBO_R: 7.8424e-01, expELBO_F: 6.3991e-01, Kl_F: 2446.9978, KL_R: 1216.5425 DIFF_Kl_F: 1159.5725\n",
      "\n",
      "Epoch[55](7/8): time: 1212.3092: Rec: 120601.5312, Kl_E: 40.0779, expELBO_R: 7.4951e-01, expELBO_F: 6.4209e-01, Kl_F: 2019.6332, KL_R: 13725.0352 DIFF_Kl_F: 13684.9570\n",
      "\n",
      "Epoch[56](7/8): time: 1233.5771: Rec: 145934.1562, Kl_E: 90.2832, expELBO_R: 7.6465e-01, expELBO_F: 6.6458e-01, Kl_F: 2211.6672, KL_R: 921.3838 DIFF_Kl_F: 831.1006\n",
      "\n",
      "Epoch[57](7/8): time: 1254.8310: Rec: 120766.2891, Kl_E: 61.0164, expELBO_R: 6.9578e-01, expELBO_F: 6.6607e-01, Kl_F: 1744.5963, KL_R: 2637.0183 DIFF_Kl_F: 2576.0020\n",
      "\n",
      "Epoch[58](7/8): time: 1276.2033: Rec: 126023.0625, Kl_E: 109.8016, expELBO_R: 7.0511e-01, expELBO_F: 6.1236e-01, Kl_F: 1718.4395, KL_R: 4164.9561 DIFF_Kl_F: 4055.1545\n",
      "\n",
      "Epoch[59](7/8): time: 1297.5851: Rec: 148190.4219, Kl_E: 89.1181, expELBO_R: 8.3795e-01, expELBO_F: 6.9587e-01, Kl_F: 6178.7275, KL_R: 1420.7816 DIFF_Kl_F: 1331.6635\n",
      "\n",
      "Epoch[60](7/8): time: 1318.9607: Rec: 128166.7188, Kl_E: 129.6214, expELBO_R: 7.5414e-01, expELBO_F: 6.8042e-01, Kl_F: 633.2552, KL_R: 183.1345 DIFF_Kl_F: 53.5130\n",
      "\n",
      "Epoch[61](7/8): time: 1340.1805: Rec: 124912.8828, Kl_E: 63.3019, expELBO_R: 7.2880e-01, expELBO_F: 6.3326e-01, Kl_F: 656.5201, KL_R: 915.3489 DIFF_Kl_F: 852.0469\n",
      "\n",
      "Epoch[62](7/8): time: 1361.3532: Rec: 102391.4219, Kl_E: 70.5908, expELBO_R: 6.3749e-01, expELBO_F: 6.6385e-01, Kl_F: 242.5319, KL_R: 379.0003 DIFF_Kl_F: 308.4095\n",
      "\n",
      "Epoch[63](7/8): time: 1383.2633: Rec: 153649.8438, Kl_E: 197.5220, expELBO_R: 7.8962e-01, expELBO_F: 6.0955e-01, Kl_F: 1555.5784, KL_R: 213.8610 DIFF_Kl_F: 16.3389\n",
      "\n",
      "Epoch[64](7/8): time: 1404.5782: Rec: 151344.0781, Kl_E: 85.7405, expELBO_R: 7.6945e-01, expELBO_F: 6.6034e-01, Kl_F: 2253.9622, KL_R: 800.9733 DIFF_Kl_F: 715.2328\n",
      "\n",
      "Epoch[65](7/8): time: 1426.5594: Rec: 150152.9688, Kl_E: 86.9094, expELBO_R: 7.6615e-01, expELBO_F: 7.2979e-01, Kl_F: 2857.1653, KL_R: 1344.3661 DIFF_Kl_F: 1257.4567\n",
      "\n",
      "Epoch[66](7/8): time: 1447.7792: Rec: 149526.1562, Kl_E: 138.8111, expELBO_R: 8.4268e-01, expELBO_F: 6.1827e-01, Kl_F: 3253.6545, KL_R: 158.4617 DIFF_Kl_F: 19.6506\n",
      "\n",
      "Epoch[67](7/8): time: 1468.9675: Rec: 125062.2656, Kl_E: 61.6778, expELBO_R: 6.8452e-01, expELBO_F: 6.8576e-01, Kl_F: 1142.5245, KL_R: 4005.4414 DIFF_Kl_F: 3943.7637\n",
      "\n",
      "Epoch[68](7/8): time: 1490.8798: Rec: 148448.1562, Kl_E: 80.8187, expELBO_R: 8.2748e-01, expELBO_F: 5.4676e-01, Kl_F: 2088.0286, KL_R: 1054.2817 DIFF_Kl_F: 973.4630\n",
      "\n",
      "Epoch[69](7/8): time: 1512.5619: Rec: 128751.9922, Kl_E: 53.1341, expELBO_R: 7.4164e-01, expELBO_F: 5.9017e-01, Kl_F: 948.8668, KL_R: 2726.6560 DIFF_Kl_F: 2673.5220\n",
      "\n",
      "Epoch[70](7/8): time: 1533.7432: Rec: 142512.0156, Kl_E: 140.1932, expELBO_R: 7.6863e-01, expELBO_F: 5.8707e-01, Kl_F: 3284.2913, KL_R: 436.3640 DIFF_Kl_F: 296.1707\n",
      "\n",
      "Epoch[71](7/8): time: 1555.5680: Rec: 141181.8281, Kl_E: 102.4869, expELBO_R: 7.6376e-01, expELBO_F: 5.7932e-01, Kl_F: 2179.3889, KL_R: 417.5755 DIFF_Kl_F: 315.0886\n",
      "\n",
      "Epoch[72](7/8): time: 1576.8870: Rec: 142175.0938, Kl_E: 54.1448, expELBO_R: 7.7742e-01, expELBO_F: 6.9531e-01, Kl_F: 4468.9878, KL_R: 10780.5801 DIFF_Kl_F: 10726.4355\n",
      "\n",
      "Epoch[73](7/8): time: 1598.5270: Rec: 118242.5156, Kl_E: 92.7841, expELBO_R: 7.0712e-01, expELBO_F: 5.9531e-01, Kl_F: 1443.7288, KL_R: 1773.4872 DIFF_Kl_F: 1680.7031\n",
      "\n",
      "Epoch[74](7/8): time: 1619.8674: Rec: 117446.7656, Kl_E: 51.3184, expELBO_R: 7.1792e-01, expELBO_F: 7.2162e-01, Kl_F: 1245.0929, KL_R: 1051.4054 DIFF_Kl_F: 1000.0870\n",
      "\n",
      "Epoch[75](7/8): time: 1641.6791: Rec: 147035.5781, Kl_E: 81.2017, expELBO_R: 7.6407e-01, expELBO_F: 6.0924e-01, Kl_F: 4002.7642, KL_R: 788.8090 DIFF_Kl_F: 707.6073\n",
      "\n",
      "Epoch[76](7/8): time: 1662.9227: Rec: 114744.7031, Kl_E: 50.7180, expELBO_R: 6.6755e-01, expELBO_F: 6.3545e-01, Kl_F: 5821.2866, KL_R: 4143.3618 DIFF_Kl_F: 4092.6438\n",
      "\n",
      "Epoch[77](7/8): time: 1684.1973: Rec: 123324.5469, Kl_E: 79.0311, expELBO_R: 6.9800e-01, expELBO_F: 6.3746e-01, Kl_F: 1619.8956, KL_R: 18211.3223 DIFF_Kl_F: 18132.2910\n",
      "\n",
      "Epoch[78](7/8): time: 1705.4787: Rec: 123570.9297, Kl_E: 91.3516, expELBO_R: 7.4266e-01, expELBO_F: 6.2401e-01, Kl_F: 802.8513, KL_R: 1385.3004 DIFF_Kl_F: 1293.9489\n",
      "\n",
      "Epoch[79](7/8): time: 1726.6702: Rec: 149601.8281, Kl_E: 192.1961, expELBO_R: 8.1513e-01, expELBO_F: 7.0826e-01, Kl_F: 2366.5400, KL_R: 1408.0378 DIFF_Kl_F: 1215.8418\n",
      "\n",
      "Epoch[80](7/8): time: 1747.8670: Rec: 135346.3750, Kl_E: 44.6669, expELBO_R: 7.8113e-01, expELBO_F: 5.3129e-01, Kl_F: 3815.4263, KL_R: 357.5786 DIFF_Kl_F: 312.9117\n",
      "\n",
      "Epoch[81](7/8): time: 1769.0903: Rec: 137549.0938, Kl_E: 180.6817, expELBO_R: 7.2030e-01, expELBO_F: 6.6775e-01, Kl_F: 3710.3806, KL_R: 1344.9417 DIFF_Kl_F: 1164.2600\n",
      "\n",
      "Epoch[82](7/8): time: 1790.8921: Rec: 115197.0312, Kl_E: 52.0857, expELBO_R: 6.6530e-01, expELBO_F: 7.3343e-01, Kl_F: 266.5267, KL_R: 163.6397 DIFF_Kl_F: 111.5540\n",
      "\n",
      "Epoch[83](7/8): time: 1812.0944: Rec: 127165.8359, Kl_E: 46.9554, expELBO_R: 7.1956e-01, expELBO_F: 6.7559e-01, Kl_F: 1426.4906, KL_R: 633.6362 DIFF_Kl_F: 586.6808\n",
      "\n",
      "Epoch[84](7/8): time: 1833.2459: Rec: 127265.4219, Kl_E: 74.8089, expELBO_R: 7.3140e-01, expELBO_F: 6.0702e-01, Kl_F: 1576.5031, KL_R: 217.5494 DIFF_Kl_F: 142.7406\n",
      "\n",
      "Epoch[85](7/8): time: 1854.4751: Rec: 137398.8594, Kl_E: 78.4437, expELBO_R: 8.1144e-01, expELBO_F: 5.6535e-01, Kl_F: 3272.8892, KL_R: 1093.4905 DIFF_Kl_F: 1015.0468\n",
      "\n",
      "Epoch[86](7/8): time: 1875.6993: Rec: 146538.7812, Kl_E: 125.6881, expELBO_R: 8.0484e-01, expELBO_F: 6.3718e-01, Kl_F: 4917.4956, KL_R: 1738.4294 DIFF_Kl_F: 1612.7413\n",
      "\n",
      "Epoch[87](7/8): time: 1897.5214: Rec: 141793.5469, Kl_E: 222.5493, expELBO_R: 7.9311e-01, expELBO_F: 7.6436e-01, Kl_F: 3483.5422, KL_R: 551.3914 DIFF_Kl_F: 328.8420\n",
      "\n",
      "Epoch[88](7/8): time: 1918.8381: Rec: 142418.3750, Kl_E: 71.1069, expELBO_R: 7.8001e-01, expELBO_F: 6.5373e-01, Kl_F: 4767.0767, KL_R: 1199.1863 DIFF_Kl_F: 1128.0793\n",
      "\n",
      "Epoch[89](7/8): time: 1940.8616: Rec: 141939.1875, Kl_E: 150.9180, expELBO_R: 7.7483e-01, expELBO_F: 5.6554e-01, Kl_F: 3606.5684, KL_R: 2349.6069 DIFF_Kl_F: 2198.6890\n",
      "\n",
      "Epoch[90](7/8): time: 1962.1349: Rec: 135133.7656, Kl_E: 170.1105, expELBO_R: 7.7231e-01, expELBO_F: 6.3757e-01, Kl_F: 2215.3816, KL_R: 2595.6851 DIFF_Kl_F: 2425.5745\n",
      "\n",
      "Epoch[91](7/8): time: 1983.9664: Rec: 145027.2031, Kl_E: 58.4926, expELBO_R: 7.5146e-01, expELBO_F: 6.0575e-01, Kl_F: 5424.9199, KL_R: 9414.3398 DIFF_Kl_F: 9355.8477\n",
      "\n",
      "Epoch[92](7/8): time: 2005.3304: Rec: 117778.6406, Kl_E: 75.6936, expELBO_R: 8.1032e-01, expELBO_F: 6.5878e-01, Kl_F: 2194.8430, KL_R: 6183.4634 DIFF_Kl_F: 6107.7695\n",
      "\n",
      "Epoch[93](7/8): time: 2026.5714: Rec: 124843.8281, Kl_E: 54.6772, expELBO_R: 6.7936e-01, expELBO_F: 6.6837e-01, Kl_F: 3360.6560, KL_R: 2362.7822 DIFF_Kl_F: 2308.1050\n",
      "\n",
      "Epoch[94](7/8): time: 2047.7966: Rec: 137765.6875, Kl_E: 56.2405, expELBO_R: 8.2269e-01, expELBO_F: 6.8551e-01, Kl_F: 3263.0325, KL_R: 317.9449 DIFF_Kl_F: 261.7044\n",
      "\n",
      "Epoch[95](7/8): time: 2069.5071: Rec: 122364.4375, Kl_E: 75.4624, expELBO_R: 6.5229e-01, expELBO_F: 6.3751e-01, Kl_F: 4355.7036, KL_R: 3907.5488 DIFF_Kl_F: 3832.0864\n",
      "\n",
      "Epoch[96](7/8): time: 2090.8095: Rec: 135492.0938, Kl_E: 90.1608, expELBO_R: 7.5699e-01, expELBO_F: 6.5455e-01, Kl_F: 2051.8792, KL_R: 172.6689 DIFF_Kl_F: 82.5081\n",
      "\n",
      "Epoch[97](7/8): time: 2112.4682: Rec: 121150.4141, Kl_E: 112.7514, expELBO_R: 6.7716e-01, expELBO_F: 6.3310e-01, Kl_F: 1735.6719, KL_R: 1201.3297 DIFF_Kl_F: 1088.5784\n",
      "\n",
      "Epoch[98](7/8): time: 2134.1072: Rec: 133869.0781, Kl_E: 76.5964, expELBO_R: 7.6270e-01, expELBO_F: 7.0386e-01, Kl_F: 2067.5200, KL_R: 172.4138 DIFF_Kl_F: 95.8175\n",
      "\n",
      "Epoch[99](7/8): time: 2155.4232: Rec: 150771.9219, Kl_E: 190.1698, expELBO_R: 7.8363e-01, expELBO_F: 6.4655e-01, Kl_F: 2571.7659, KL_R: 186.0144 DIFF_Kl_F: -4.1554\n",
      "\n",
      "Epoch[100](7/8): time: 2177.5349: Rec: 145849.5156, Kl_E: 381.7177, expELBO_R: 8.4291e-01, expELBO_F: 6.0523e-01, Kl_F: 3045.6086, KL_R: 1960.0851 DIFF_Kl_F: 1578.3673\n",
      "\n",
      "Epoch[101](7/8): time: 2198.7828: Rec: 139763.6406, Kl_E: 116.9672, expELBO_R: 7.6951e-01, expELBO_F: 5.9945e-01, Kl_F: 3991.7627, KL_R: 701.4905 DIFF_Kl_F: 584.5233\n",
      "\n",
      "Epoch[102](7/8): time: 2220.1031: Rec: 144401.4531, Kl_E: 71.6450, expELBO_R: 7.5455e-01, expELBO_F: 6.4806e-01, Kl_F: 5063.1592, KL_R: 917.3582 DIFF_Kl_F: 845.7131\n",
      "\n",
      "Epoch[103](7/8): time: 2242.2897: Rec: 112913.7188, Kl_E: 47.3616, expELBO_R: 7.1057e-01, expELBO_F: 6.7688e-01, Kl_F: 552.3847, KL_R: 940.0219 DIFF_Kl_F: 892.6603\n",
      "\n",
      "Epoch[104](7/8): time: 2263.6421: Rec: 139939.7812, Kl_E: 163.7538, expELBO_R: 7.7726e-01, expELBO_F: 7.0010e-01, Kl_F: 8703.8252, KL_R: 2046.8813 DIFF_Kl_F: 1883.1276\n",
      "\n",
      "Epoch[105](7/8): time: 2284.8634: Rec: 150987.3594, Kl_E: 220.1260, expELBO_R: 8.0673e-01, expELBO_F: 7.2775e-01, Kl_F: 4157.6299, KL_R: 1400.3746 DIFF_Kl_F: 1180.2487\n",
      "\n",
      "Epoch[106](7/8): time: 2306.6202: Rec: 150128.0781, Kl_E: 114.7951, expELBO_R: 8.7455e-01, expELBO_F: 7.2331e-01, Kl_F: 3703.3948, KL_R: 2044.6544 DIFF_Kl_F: 1929.8594\n",
      "\n",
      "Epoch[107](7/8): time: 2327.8677: Rec: 132315.0781, Kl_E: 53.1323, expELBO_R: 7.2661e-01, expELBO_F: 7.0589e-01, Kl_F: 3044.1404, KL_R: 867.8968 DIFF_Kl_F: 814.7645\n",
      "\n",
      "Epoch[108](7/8): time: 2349.1443: Rec: 121051.2188, Kl_E: 62.4430, expELBO_R: 7.0489e-01, expELBO_F: 7.4703e-01, Kl_F: 1832.5099, KL_R: 216.2369 DIFF_Kl_F: 153.7940\n",
      "\n",
      "Epoch[109](7/8): time: 2370.3450: Rec: 130133.3281, Kl_E: 131.0629, expELBO_R: 7.3991e-01, expELBO_F: 7.2793e-01, Kl_F: 5418.9556, KL_R: 1218.2484 DIFF_Kl_F: 1087.1855\n",
      "\n",
      "Epoch[110](7/8): time: 2392.2352: Rec: 145759.1094, Kl_E: 169.0946, expELBO_R: 8.0430e-01, expELBO_F: 6.8869e-01, Kl_F: 5814.5552, KL_R: 455.5370 DIFF_Kl_F: 286.4424\n",
      "\n",
      "Epoch[111](7/8): time: 2414.0512: Rec: 138802.8438, Kl_E: 73.6095, expELBO_R: 7.7795e-01, expELBO_F: 6.9038e-01, Kl_F: 9014.7627, KL_R: 4215.7710 DIFF_Kl_F: 4142.1616\n",
      "\n",
      "Epoch[112](7/8): time: 2435.3208: Rec: 135794.0781, Kl_E: 79.8746, expELBO_R: 7.7188e-01, expELBO_F: 6.7699e-01, Kl_F: 1676.1288, KL_R: 1000.3940 DIFF_Kl_F: 920.5193\n",
      "\n",
      "Epoch[113](7/8): time: 2457.3147: Rec: 128503.1641, Kl_E: 58.3107, expELBO_R: 7.9599e-01, expELBO_F: 6.0683e-01, Kl_F: 2764.7871, KL_R: 163.8584 DIFF_Kl_F: 105.5477\n",
      "\n",
      "Epoch[114](7/8): time: 2478.5314: Rec: 149083.0000, Kl_E: 110.1969, expELBO_R: 7.8788e-01, expELBO_F: 5.9259e-01, Kl_F: 5965.8604, KL_R: 1045.3696 DIFF_Kl_F: 935.1728\n",
      "\n",
      "Epoch[115](7/8): time: 2500.2308: Rec: 121333.6875, Kl_E: 108.3955, expELBO_R: 6.0040e-01, expELBO_F: 6.8568e-01, Kl_F: 914.4348, KL_R: 556.6752 DIFF_Kl_F: 448.2798\n",
      "\n",
      "Epoch[116](7/8): time: 2522.0822: Rec: 120192.4375, Kl_E: 122.3011, expELBO_R: 7.2171e-01, expELBO_F: 6.4808e-01, Kl_F: 796.6036, KL_R: 334.1631 DIFF_Kl_F: 211.8620\n",
      "\n",
      "Epoch[117](7/8): time: 2544.0233: Rec: 149465.3125, Kl_E: 279.2386, expELBO_R: 8.1973e-01, expELBO_F: 6.3074e-01, Kl_F: 6401.8174, KL_R: 344.8191 DIFF_Kl_F: 65.5805\n",
      "\n",
      "Epoch[118](7/8): time: 2565.2569: Rec: 145744.8438, Kl_E: 201.1314, expELBO_R: 7.5141e-01, expELBO_F: 6.5536e-01, Kl_F: 3748.4993, KL_R: 137.2521 DIFF_Kl_F: -63.8793\n",
      "\n",
      "Epoch[119](7/8): time: 2586.5044: Rec: 104720.1484, Kl_E: 75.7672, expELBO_R: 5.9390e-01, expELBO_F: 6.3799e-01, Kl_F: 5882.8081, KL_R: 3125.7400 DIFF_Kl_F: 3049.9727\n",
      "\n",
      "Epoch[120](7/8): time: 2607.6744: Rec: 132217.7969, Kl_E: 91.0198, expELBO_R: 7.4798e-01, expELBO_F: 7.2131e-01, Kl_F: 2647.9878, KL_R: 513.4632 DIFF_Kl_F: 422.4434\n",
      "\n",
      "Epoch[121](7/8): time: 2628.9680: Rec: 142363.9688, Kl_E: 222.3784, expELBO_R: 8.2569e-01, expELBO_F: 6.8293e-01, Kl_F: 4842.4380, KL_R: 1105.7936 DIFF_Kl_F: 883.4152\n",
      "\n",
      "Epoch[122](7/8): time: 2650.8726: Rec: 135591.8906, Kl_E: 68.6019, expELBO_R: 7.6105e-01, expELBO_F: 6.0643e-01, Kl_F: 3448.2112, KL_R: 387.8695 DIFF_Kl_F: 319.2675\n",
      "\n",
      "Epoch[123](7/8): time: 2672.0754: Rec: 145600.3750, Kl_E: 221.7711, expELBO_R: 7.7044e-01, expELBO_F: 6.0292e-01, Kl_F: 5094.6997, KL_R: 885.2729 DIFF_Kl_F: 663.5018\n",
      "\n",
      "Epoch[124](7/8): time: 2694.1229: Rec: 130661.3047, Kl_E: 50.2447, expELBO_R: 7.6939e-01, expELBO_F: 6.7203e-01, Kl_F: 7794.8267, KL_R: 1563.0999 DIFF_Kl_F: 1512.8551\n",
      "\n",
      "Epoch[125](7/8): time: 2716.0605: Rec: 146918.1875, Kl_E: 208.7380, expELBO_R: 7.9038e-01, expELBO_F: 6.3842e-01, Kl_F: 19793.1895, KL_R: 716.0681 DIFF_Kl_F: 507.3301\n",
      "\n",
      "Epoch[126](7/8): time: 2737.2090: Rec: 146841.6406, Kl_E: 269.3608, expELBO_R: 7.8639e-01, expELBO_F: 7.0002e-01, Kl_F: 8048.2544, KL_R: 262.4680 DIFF_Kl_F: -6.8928\n",
      "\n",
      "Epoch[127](7/8): time: 2758.8956: Rec: 123787.1797, Kl_E: 63.4139, expELBO_R: 7.8209e-01, expELBO_F: 6.8778e-01, Kl_F: 1101.8005, KL_R: 3826.2839 DIFF_Kl_F: 3762.8701\n",
      "\n",
      "Epoch[128](7/8): time: 2780.8507: Rec: 118232.9688, Kl_E: 56.9333, expELBO_R: 6.5481e-01, expELBO_F: 6.7187e-01, Kl_F: 779.1612, KL_R: 1191.2065 DIFF_Kl_F: 1134.2732\n",
      "\n",
      "Epoch[129](7/8): time: 2802.0808: Rec: 128114.7031, Kl_E: 143.6355, expELBO_R: 7.7546e-01, expELBO_F: 7.0757e-01, Kl_F: 2862.1904, KL_R: 1434.3524 DIFF_Kl_F: 1290.7169\n",
      "\n",
      "Epoch[130](7/8): time: 2823.3069: Rec: 146592.9375, Kl_E: 68.0642, expELBO_R: 8.1013e-01, expELBO_F: 7.3845e-01, Kl_F: 8872.2256, KL_R: 2265.9585 DIFF_Kl_F: 2197.8943\n",
      "\n",
      "Epoch[131](7/8): time: 2845.1842: Rec: 148458.9531, Kl_E: 135.6681, expELBO_R: 7.9085e-01, expELBO_F: 6.8945e-01, Kl_F: 5474.2637, KL_R: 199.3156 DIFF_Kl_F: 63.6475\n",
      "\n",
      "Epoch[132](7/8): time: 2867.2200: Rec: 118507.3750, Kl_E: 54.4049, expELBO_R: 7.0464e-01, expELBO_F: 5.9594e-01, Kl_F: 517.7036, KL_R: 754.8165 DIFF_Kl_F: 700.4116\n",
      "\n",
      "Epoch[133](7/8): time: 2888.4580: Rec: 144084.8594, Kl_E: 186.9026, expELBO_R: 7.8641e-01, expELBO_F: 7.0785e-01, Kl_F: 3472.1372, KL_R: 910.5330 DIFF_Kl_F: 723.6303\n",
      "\n",
      "Epoch[134](7/8): time: 2909.8542: Rec: 141477.0625, Kl_E: 134.9345, expELBO_R: 7.9699e-01, expELBO_F: 6.0405e-01, Kl_F: 3090.4109, KL_R: 899.8523 DIFF_Kl_F: 764.9178\n",
      "\n",
      "Epoch[135](7/8): time: 2931.1321: Rec: 134053.4688, Kl_E: 69.4403, expELBO_R: 7.3754e-01, expELBO_F: 7.4131e-01, Kl_F: 3858.0583, KL_R: 1014.1501 DIFF_Kl_F: 944.7099\n",
      "\n",
      "Epoch[136](7/8): time: 2952.4674: Rec: 144926.2188, Kl_E: 217.8722, expELBO_R: 7.8515e-01, expELBO_F: 6.2170e-01, Kl_F: 11224.4971, KL_R: 845.0991 DIFF_Kl_F: 627.2269\n",
      "\n",
      "Epoch[137](7/8): time: 2974.4733: Rec: 128697.7109, Kl_E: 82.6500, expELBO_R: 7.2405e-01, expELBO_F: 6.5265e-01, Kl_F: 1780.2095, KL_R: 192.9449 DIFF_Kl_F: 110.2948\n",
      "\n",
      "Epoch[138](7/8): time: 2995.8681: Rec: 125347.4453, Kl_E: 50.0814, expELBO_R: 7.7138e-01, expELBO_F: 6.4651e-01, Kl_F: 2620.1611, KL_R: 494.3372 DIFF_Kl_F: 444.2558\n",
      "\n",
      "Epoch[139](7/8): time: 3017.3048: Rec: 143743.2500, Kl_E: 464.0246, expELBO_R: 7.8159e-01, expELBO_F: 6.8152e-01, Kl_F: 8016.1221, KL_R: 403.8878 DIFF_Kl_F: -60.1367\n",
      "\n",
      "Epoch[140](7/8): time: 3039.2695: Rec: 101475.8594, Kl_E: 55.3254, expELBO_R: 6.7880e-01, expELBO_F: 7.3008e-01, Kl_F: 258.5345, KL_R: 1369.2001 DIFF_Kl_F: 1313.8746\n",
      "\n",
      "Epoch[141](7/8): time: 3061.1952: Rec: 122157.7578, Kl_E: 46.0228, expELBO_R: 7.4885e-01, expELBO_F: 6.7696e-01, Kl_F: 603.1315, KL_R: 293.0238 DIFF_Kl_F: 247.0010\n",
      "\n",
      "Epoch[142](7/8): time: 3082.6703: Rec: 146106.2500, Kl_E: 110.3885, expELBO_R: 7.7266e-01, expELBO_F: 6.4008e-01, Kl_F: 5989.7759, KL_R: 590.4360 DIFF_Kl_F: 480.0475\n",
      "\n",
      "Epoch[143](7/8): time: 3103.9549: Rec: 115238.2188, Kl_E: 65.8083, expELBO_R: 7.3810e-01, expELBO_F: 6.7319e-01, Kl_F: 888.1651, KL_R: 335.7104 DIFF_Kl_F: 269.9020\n",
      "\n",
      "Epoch[144](7/8): time: 3125.4464: Rec: 145748.9844, Kl_E: 207.9367, expELBO_R: 8.2470e-01, expELBO_F: 5.8087e-01, Kl_F: 5369.8960, KL_R: 2937.0481 DIFF_Kl_F: 2729.1113\n",
      "\n",
      "Epoch[145](7/8): time: 3147.0266: Rec: 127178.2578, Kl_E: 98.6847, expELBO_R: 7.6365e-01, expELBO_F: 6.4784e-01, Kl_F: 6826.9194, KL_R: 845.4594 DIFF_Kl_F: 746.7747\n",
      "\n",
      "Epoch[146](7/8): time: 3168.4369: Rec: 143414.5000, Kl_E: 103.2472, expELBO_R: 8.0491e-01, expELBO_F: 5.6288e-01, Kl_F: 6855.7324, KL_R: 404.1498 DIFF_Kl_F: 300.9026\n",
      "\n",
      "Epoch[147](7/8): time: 3189.6494: Rec: 132586.2812, Kl_E: 113.0329, expELBO_R: 7.9638e-01, expELBO_F: 6.7581e-01, Kl_F: 18629.8164, KL_R: 1028.9506 DIFF_Kl_F: 915.9177\n",
      "\n",
      "Epoch[148](7/8): time: 3210.8396: Rec: 117636.1328, Kl_E: 47.9734, expELBO_R: 7.5846e-01, expELBO_F: 6.1733e-01, Kl_F: 882.8828, KL_R: 1855.5447 DIFF_Kl_F: 1807.5713\n",
      "\n",
      "Epoch[149](7/8): time: 3231.9598: Rec: 143886.3750, Kl_E: 502.3283, expELBO_R: 8.0221e-01, expELBO_F: 5.7949e-01, Kl_F: 5644.5996, KL_R: 1097.8682 DIFF_Kl_F: 595.5399\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "num_epochs = 150\n",
    "lr = 2e-4\n",
    "batch_size = 16\n",
    "beta_kl = 1.0\n",
    "beta_rec = 1.0\n",
    "beta_neg = 256\n",
    "\n",
    "model = train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=batch_size, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                                 num_epochs=num_epochs, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                                 beta_kl=beta_kl, beta_rec=beta_rec, beta_neg=beta_neg, test_iter=1000, seed=-1, pretrained=None,\n",
    "                                 device=device)\n",
    "# train soft intro vae の引数の中にpretrainedがあるが、指定すれば呼べる？？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a30c215-7515-4bc8-bde1-075d612240a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that these results are for 150 epochs, usually more is needed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 1, 5, 6, 5]' is invalid for input of size 9600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m     noise_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(size\u001b[38;5;241m=\u001b[39m(num_samples, model\u001b[38;5;241m.\u001b[39mzdim))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m     images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(images \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mSoftIntroVAE.sample\u001b[0;34m(self, z, y_cond)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, y_cond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# x.view(-1, 2) \u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# batchsize, channel, 5×6×5 (150)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z, y_cond\u001b[38;5;241m=\u001b[39my_cond)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 1, 5, 6, 5]' is invalid for input of size 9600"
     ]
    }
   ],
   "source": [
    "# generate samples\n",
    "print(\"Note that these results are for 150 epochs, usually more is needed.\")\n",
    "num_samples = 64\n",
    "with torch.no_grad():\n",
    "    noise_batch = torch.randn(size=(num_samples, model.zdim)).to(device)\n",
    "    images = model.sample(noise_batch)\n",
    "    images = images.data.cpu().numpy()\n",
    "    images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    images = images / 255.0\n",
    "    images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "    grid = make_grid(images, nrow=8)\n",
    "    \n",
    "grid_np = grid.permute(1, 2, 0).data.cpu().numpy()   \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_generated.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee21f3f-05ed-4dcc-a38a-b6a6db62fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reconstructions\n",
    "# num_recon = 8\n",
    "# test_dataset = CIFAR10(root='./cifar10_ds', train=False, download=True, transform=transforms.ToTensor())\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=num_recon, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "# test_images = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3c967-de2e-46a6-bf44-76a32b142939",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    total_grid = []\n",
    "    for _ in range(3):\n",
    "        data = next(test_images)\n",
    "        recon = model(data[0].to(device), deterministic=True)[3]\n",
    "        images = recon.data.cpu().numpy()\n",
    "        images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "        images = images / 255.0\n",
    "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "        grid = make_grid(torch.cat([data[0], images], dim=0), nrow=8)\n",
    "        total_grid.append(grid)\n",
    "    \n",
    "total_grid = torch.cat(total_grid, dim=1)\n",
    "grid_np = total_grid.permute(1, 2, 0).data.cpu().numpy()  \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_reconstructions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8907a-3008-4331-8ac1-98a8a331db7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8bd17-d77c-46a9-b0bb-edb46a5d94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8966a1-c4f9-4e36-92ad-5791d374e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "83703930f6dd6eb5d91c8a9abe31f591cc3731721361839549be9d5bb51ffcf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
