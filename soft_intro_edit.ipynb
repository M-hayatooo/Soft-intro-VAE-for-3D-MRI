{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438abb3-7f9a-4c4c-92a9-e64527ebcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import models.models as models\n",
    "import utils.confusion as confusion\n",
    "import utils.my_trainer as trainer\n",
    "import utils.train_result as train_result\n",
    "from datasets.dataset import load_data\n",
    "from utils.data_class import BrainDataset\n",
    "\n",
    "# import os.path as osp\n",
    "import torchio as tio\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from torchio.transforms.augmentation.intensity.random_bias_field import RandomBiasField\n",
    "from torchio.transforms.augmentation.intensity.random_noise import RandomNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d10d4-2eae-4c48-8701-0b5a17688954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True #この行をFalseにすると再現性はとれるが、速度が落ちる\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return\n",
    "fix_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac9304-9a2d-4025-9769-a2c150f00c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\"CN\": 0, \"AD\": 1}\n",
    "SEED_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e817a-4014-45db-993d-f68de351b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(kinds=[\"ADNI2\"], classes=[\"CN\"], unique=False, blacklist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20bcf3d-6f50-4ad1-8609-a1d09de8822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = []\n",
    "voxels = np.zeros((len(data), 80, 96, 80))\n",
    "labels = np.zeros(len(data))\n",
    "for i in tqdm(range(len(data))):\n",
    "    pids.append(data[i][\"pid\"])\n",
    "    voxels[i] = data[i][\"voxel\"]\n",
    "    labels[i] = CLASS_MAP[data[i][\"label\"]]\n",
    "pids = np.array(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe1bef-13a2-4acf-9cc9-14bfcb91136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import CLASS_MAP\n",
    "from torch.utils.data import Dataset\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, voxels, labels, transform=None):\n",
    "        self.voxels = voxels\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.voxels)\n",
    "    def __getitem__(self, index):\n",
    "        voxel = self.voxels[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            voxel = self.transform(voxel, self.phase)\n",
    "        voxel = self._preprocess(voxel)\n",
    "        return voxel, label\n",
    "    def _preprocess(self, voxel):\n",
    "        cut_range = 4\n",
    "        voxel = np.clip(voxel, 0, cut_range * np.std(voxel))\n",
    "        voxel = normalize(voxel, np.min(voxel), np.max(voxel))\n",
    "        voxel = voxel[np.newaxis, ]\n",
    "        return voxel.astype('f')\n",
    "    def __call__(self, index):\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    \n",
    "def normalize(voxel: np.ndarray, floor: int, ceil: int) -> np.ndarray:\n",
    "    return (voxel - floor) / (ceil - floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51db581-d3bc-46d7-941f-43f461c2f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "tid, vid = list(gss.split(voxels, groups=pids))[0]\n",
    "train_voxels = voxels[tid]\n",
    "val_voxels = voxels[vid]\n",
    "train_labels = labels[tid]\n",
    "val_labels = labels[vid]\n",
    "\n",
    "train_dataset = BrainDataset(train_voxels, train_labels)\n",
    "val_dataset = BrainDataset(val_voxels, val_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963cce0-f8c3-4427-ac93-b50696987aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2 ** 32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "# g = torch.Generator()\n",
    "# g.manual_seed(0)\n",
    "\n",
    "# num_workers = 2\n",
    "# batch_size = 16\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=seed_worker, generator=g)\n",
    "# val_dataloader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbef25-4291-4b17-8bae-f9072150bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_kl(logvar, mu, mu_o=0.0, logvar_o=0.0, reduce='sum'):\n",
    "    if not isinstance(mu_o, torch.Tensor):\n",
    "        mu_o = torch.tensor(mu_o).to(mu.device)\n",
    "    if not isinstance(logvar_o, torch.Tensor):\n",
    "        logvar_o = torch.tensor(logvar_o).to(mu.device)\n",
    "    kl = -0.5 * (1 + logvar - logvar_o - logvar.exp() / torch.exp(logvar_o) - (mu - mu_o).pow(2) / torch.exp(\n",
    "        logvar_o)).sum(1)\n",
    "    if reduce == 'sum':\n",
    "        kl = torch.sum(kl)\n",
    "    elif reduce == 'mean':\n",
    "        kl = torch.mean(kl)\n",
    "    return kl\n",
    "\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    \"\"\"\n",
    "    This function applies the reparameterization trick:\n",
    "    z = mu(X) + sigma(X)^0.5 * epsilon, where epsilon ~ N(0,I)\n",
    "    :param mu: mean of x\n",
    "    :param logvar: log variaance of x\n",
    "    :return z: the sampled latent variable\n",
    "    \"\"\"\n",
    "    device = mu.device\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std).to(device)\n",
    "    return mu + eps * std\n",
    "\n",
    "\n",
    "def calc_reconstruction_loss(x, recon_x, loss_type='mse', reduction='mean'):\n",
    "    x = x.view(x.size(0), -1)\n",
    "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    \n",
    "    recon_error = F.mse_loss(recon_x, x, reduction='none')\n",
    "    recon_error = recon_error.sum(1)\n",
    "    recon_error = recon_error.mean()\n",
    "    return recon_error\n",
    "\n",
    "\n",
    "def load_model(model, pretrained, device):\n",
    "    weights = torch.load(pretrained, map_location=device)\n",
    "    model.load_state_dict(weights['model'], strict=False)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, epoch, iteration, prefix=\"\"):\n",
    "    model_out_path = \"./saves/\" + prefix + \"model_epoch_{}_iter_{}.pth\".format(epoch, iteration)\n",
    "    state = {\"epoch\": epoch, \"model\": model.state_dict()}\n",
    "    if not os.path.exists(\"./saves/\"):\n",
    "        os.makedirs(\"./saves/\")\n",
    "\n",
    "    torch.save(state, model_out_path)\n",
    "\n",
    "    print(\"model checkpoint saved @ {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb03b5a-217e-4434-89ab-197b3b0f4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BuildingBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(BuildingBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool3d(kernel_size=stride),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "class UpsampleBuildingkBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(UpsampleBuildingkBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, in_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=stride),\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.block_setting = block_setting\n",
    "        self.in_ch = in_ch\n",
    "        last = 1\n",
    "        blocks = [nn.Sequential(\n",
    "            nn.Conv3d(1, in_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )]\n",
    "        for line in self.block_setting:\n",
    "            c, n, s = line[0], line[1], line[2]\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(nn.Sequential(BuildingBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        self.inner_ch = in_ch\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.conv = nn.Conv3d(in_ch, last, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.blocks(x)\n",
    "        return self.conv(h)\n",
    "\n",
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, encoder: ResNetEncoder, blocks=None):\n",
    "        super(ResNetDecoder, self).__init__()\n",
    "        last = encoder.block_setting[-1][0]\n",
    "        if blocks is None:\n",
    "            blocks = [nn.Sequential(\n",
    "                nn.Conv3d(1, last, 1, 1, bias=True),\n",
    "                nn.BatchNorm3d(last),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )]\n",
    "        in_ch = last\n",
    "        for i in range(len(encoder.block_setting)):\n",
    "            if i == len(encoder.block_setting) - 1:\n",
    "                nc = encoder.in_ch\n",
    "            else:\n",
    "                nc = encoder.block_setting[::-1][i + 1][0]\n",
    "            c, n, s = encoder.block_setting[::-1][i]\n",
    "            for j in range(n):\n",
    "                stride = s if j == n - 1 else 1\n",
    "                c = nc if j == n - 1 else c\n",
    "                blocks.append(nn.Sequential(UpsampleBuildingkBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        blocks.append(nn.Sequential(\n",
    "            nn.Conv3d(in_ch, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.blocks(x)\n",
    "\n",
    "\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseEncoder, self).__init__()\n",
    "class BaseDecoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseDecoder, self).__init__()\n",
    "\n",
    "class BaseCAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseCAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "    def decode(self, z):\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        out = self.decode(z)\n",
    "        return out, z\n",
    "\n",
    "class BaseVAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseVAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "    def decode(self, vec):\n",
    "        out = self.decoder(vec)\n",
    "        return out\n",
    "    def reparameterize(self, mu, logvar) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        vec = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(vec)\n",
    "        return x_hat, vec, mu, logvar\n",
    "\n",
    "\n",
    "class ResNetCAE(BaseCAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetCAE, self).__init__()\n",
    "        self.encoder = ResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class VAEResNetEncoder(ResNetEncoder):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(VAEResNetEncoder, self).__init__(in_ch, block_setting)\n",
    "        self.mu = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "        self.var = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h = self.blocks(x)\n",
    "        mu = self.mu(h)\n",
    "        var = self.var(h)\n",
    "        return mu, var\n",
    "\n",
    "\n",
    "class ResNetVAE(BaseVAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetVAE, self).__init__()\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "\n",
    "    def reparamenterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparamenterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return x_re, mu, logvar\n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869defe-1f68-4454-80ab-3003dfcc782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftIntroVAE(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting, zdim=150, conditional=False):\n",
    "        super(SoftIntroVAE, self).__init__()\n",
    "        self.zdim = zdim\n",
    "        self.conditional = conditional\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return mu, logvar, z, x_re\n",
    "    \n",
    "#     ↑ここの forward では  RETURN {{ mu, logvar, z, y }}を返したい (soft-intro-vae-tutorial-codeでは)    \n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "            \n",
    "    def sample(self, z, y_cond=None):\n",
    "        # x.view(-1, 2) \n",
    "        z = z.view(32, 1, 5, 6, 5)# batchsize, channel, 5×6×5 (150)\n",
    "        y = self.decode(z, y_cond=y_cond)\n",
    "        return y\n",
    "\n",
    "    def sample_with_noise(self, num_samples=1, device=torch.device(\"cpu\"), y_cond=None):\n",
    "        z = torch.randn(num_samples, self.z_dim).to(device)\n",
    "        return self.decode(z, y_cond=y_cond)\n",
    "\n",
    "    def encode(self, x, o_cond=None):\n",
    "        # if self.conditional and o_cond is not None:\n",
    "        #     mu, logvar = self.encoder(x, o_cond=o_cond) # VAEResNetENcoder ⇒　return  mu, logvar\n",
    "        # else:\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z, y_cond=None):\n",
    "        # if self.conditional and y_cond is not None:\n",
    "        #     y = self.decoder(z, y_cond=y_cond)\n",
    "        # else:\n",
    "        y = self.decoder(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360a2c0-a3f8-496a-9867-be9fa9f476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=16, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                           num_epochs=250, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                           beta_kl=1.0, beta_rec=1.0, beta_neg=1.0, test_iter=1000, seed=-1, pretrained=None,\n",
    "                           device=torch.device(\"cpu\"), num_row=8, gamma_r=1e-8):\n",
    "    if seed != -1:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        print(\"random seed: \", seed)\n",
    "\n",
    "    \n",
    "    model = SoftIntroVAE(12, [ [12,1,2],[24,1,2],[32,2,2],[48,2,2] ], conditional=False)\n",
    "    #model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "    model.to(device)\n",
    "    # もしpretrainedが存在しているのならば model param load\n",
    "    if pretrained is not None: \n",
    "        load_model(model, pretrained, device)\n",
    "    print(model)\n",
    "\n",
    "    optimizer_e = optim.Adam(model.encoder.parameters(), lr=lr_e)\n",
    "    optimizer_d = optim.Adam(model.decoder.parameters(), lr=lr_d)\n",
    "\n",
    "    e_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_e, milestones=(350,), gamma=0.1)\n",
    "    d_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=(350,), gamma=0.1)\n",
    "\n",
    "    scale = 1 / (80 * 96 * 80)  # normalizing constant, 's' in the paper  desu\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
    "#   train_data_loader = load_data(kinds=[\"ADNI2\",\"ADNI2-2\"], classes=[\"CN\", \"AD\"], unique=False, blacklist=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    cur_iter = 0\n",
    "    kls_real = []\n",
    "    kls_fake = []\n",
    "    kls_rec = []\n",
    "    rec_errs = []\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        diff_kls = []\n",
    "        # save models\n",
    "        if epoch % save_interval == 0 and epoch > 0:\n",
    "            save_epoch = (epoch // save_interval) * save_interval\n",
    "            prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "            save_checkpoint(model, save_epoch, cur_iter, prefix)\n",
    "\n",
    "        model.train()\n",
    "        batch_kls_real = []\n",
    "        batch_kls_fake = []\n",
    "        batch_kls_rec = []\n",
    "        batch_rec_errs = []\n",
    "\n",
    "#        for iteration, batch in enumerate(train_data_loader, 0):\n",
    "        for iteration, (batch, labels) in enumerate(train_data_loader, 0):# iterationには 自動で割り振られたindex番号が適用される\n",
    "#        for batch, labels in train_data_loader:# iterationには 自動で割り振られたindex番号が適用される\n",
    "        # enmuerate の第２引数はindexの開始番号の指定\n",
    "        # --------------train------------\n",
    "            b_size = batch.size(0)\n",
    "\n",
    "            noise_batch = torch.randn(size=(b_size, 1, 5, 6, 5)).to(device)\n",
    "            real_batch = batch.to(device)\n",
    "\n",
    "            # =========== Update E ================\n",
    "        #   fake = model.sample(noise_batch)\n",
    "            fake = model.decode(noise_batch)\n",
    "\n",
    "            real_mu, real_logvar = model.encode(real_batch)\n",
    "            z = model.reparameterize(real_mu, real_logvar)\n",
    "            rec = model.decode(z)\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            lossE_real_kl = calc_kl(real_logvar, real_mu, reduce=\"mean\")\n",
    "            # {{ mu,    logvar,    z   ,    y }}を返す\n",
    "            rec_mu, rec_logvar, z_rec, rec_rec     = model( rec.detach())\n",
    "            fake_mu, fake_logvar, z_fake, rec_fake = model(fake.detach())\n",
    "\n",
    "            fake_kl_e = calc_kl(fake_logvar, fake_mu, reduce=\"none\")\n",
    "            rec_kl_e = calc_kl(rec_logvar, rec_mu, reduce=\"none\")\n",
    "            \n",
    "            # print(\"fake：\")\n",
    "            # print( fake.size() )\n",
    "            # print(\"rec_fake：\")\n",
    "            # print( rec_fake.size() )            \n",
    "\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake, rec_fake, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec, rec_rec, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            # loss fake rec がおかしい？\n",
    "            # print(\"loss_fake_rec：\")\n",
    "            # print( loss_fake_rec )\n",
    "            # print(\" fake_kl_e：\" )\n",
    "            # print(fake_kl_e)\n",
    "\n",
    "            exp_elbo_fake = (-2 * scale * (beta_rec * loss_fake_rec + beta_neg * fake_kl_e)).exp().mean()\n",
    "            exp_elbo_rec = (-2 * scale * (beta_rec * loss_rec_rec + beta_neg * rec_kl_e)).exp().mean()\n",
    "            # total loss\n",
    "            lossE = scale * (beta_rec * loss_rec + beta_kl * lossE_real_kl) + 0.25 * (exp_elbo_fake + exp_elbo_rec)\n",
    "            # backprop\n",
    "            optimizer_e.zero_grad()\n",
    "            lossE.backward()\n",
    "            optimizer_e.step()\n",
    "            print(\"finish updateE\")\n",
    "            # ========= Update D ==================\n",
    "            for param in model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.decoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            fake = model.decode(noise_batch)# \n",
    "            rec = model.decode(z.detach())\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec.detach(),loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_mu, rec_logvar = model.encode(rec)\n",
    "            z_rec = reparameterize(rec_mu, rec_logvar)\n",
    "\n",
    "            fake_mu, fake_logvar = model.encode(fake)\n",
    "            z_fake = reparameterize(fake_mu, fake_logvar)\n",
    "\n",
    "            # rec_rec = model.decode(z_rec.detach())\n",
    "            # rec_fake = model.decode(z_fake.detach())\n",
    "            rec_rec = model.decode(z_rec)\n",
    "            rec_fake = model.decode(z_fake)\n",
    "\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec.detach(), rec_rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake.detach(), rec_fake, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_kl = calc_kl(rec_logvar, rec_mu, reduce=\"mean\")\n",
    "            fake_kl = calc_kl(fake_logvar, fake_mu, reduce=\"mean\")\n",
    "\n",
    "            lossD = scale * (loss_rec * beta_rec + (rec_kl + fake_kl) * 0.5 * beta_kl + \\\n",
    "                                         gamma_r * 0.5 * beta_rec * (loss_rec_rec + loss_fake_rec))\n",
    "\n",
    "            optimizer_d.zero_grad()\n",
    "            lossD.backward()\n",
    "            optimizer_d.step()\n",
    "            print(\"finish updateD\")\n",
    "\n",
    "            if torch.isnan(lossD) or torch.isnan(lossE):\n",
    "                raise SystemError\n",
    "\n",
    "            # statistics for plotting later\n",
    "            diff_kls.append(-lossE_real_kl.data.cpu().item() + fake_kl.data.cpu().item())\n",
    "            batch_kls_real.append(lossE_real_kl.data.cpu().item())\n",
    "            batch_kls_fake.append(fake_kl.cpu().item())\n",
    "            batch_kls_rec.append(rec_kl.data.cpu().item())\n",
    "            batch_rec_errs.append(loss_rec.data.cpu().item())\n",
    "\n",
    "            if cur_iter % test_iter == 0:\n",
    "                info = \"\\nEpoch[{}]({}/{}): time: {:4.4f}: \".format(epoch, iteration, len(train_data_loader), time.time() - start_time)\n",
    "                info += 'Rec: {:.4f}, '.format(loss_rec.data.cpu())\n",
    "                info += 'Kl_E: {:.4f}, expELBO_R: {:.4e}, expELBO_F: {:.4e}, '.format(lossE_real_kl.data.cpu(),\n",
    "                                                                                exp_elbo_rec.data.cpu(),\n",
    "                                                                                exp_elbo_fake.cpu())\n",
    "                info += 'Kl_F: {:.4f}, KL_R: {:.4f}'.format(rec_kl.data.cpu(), fake_kl.data.cpu())\n",
    "                info += ' DIFF_Kl_F: {:.4f}'.format(-lossE_real_kl.data.cpu() + fake_kl.data.cpu())\n",
    "                print(info)\n",
    "\n",
    "                _, _, _, rec_det = model(real_batch)\n",
    "                max_imgs = min(batch.size(0), 16)\n",
    "                # vutils.save_image(\n",
    "                #         torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "                #         '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)                 \n",
    "        cur_iter += 1\n",
    "    e_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "\n",
    "    if epoch > num_vae - 1:\n",
    "        kls_real.append(np.mean(batch_kls_real))\n",
    "        kls_fake.append(np.mean(batch_kls_fake))\n",
    "        kls_rec.append(np.mean(batch_kls_rec))\n",
    "        rec_errs.append(np.mean(batch_rec_errs))\n",
    "\n",
    "#     if epoch == num_epochs - 1:\n",
    "#         with torch.no_grad():\n",
    "#             _, _, _, rec_det = model(real_batch)\n",
    "#             noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
    "#             fake = model.sample(noise_batch)\n",
    "#             max_imgs = min(batch.size(0), 16)\n",
    "#             vutils.save_image(\n",
    "#                     torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "#                     '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)\n",
    "\n",
    "#         # plot graphs\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(1, 1, 1)\n",
    "#         ax.plot(np.arange(len(kls_real)), kls_real, label=\"kl_real\")\n",
    "#         ax.plot(np.arange(len(kls_fake)), kls_fake, label=\"kl_fake\")\n",
    "#         ax.plot(np.arange(len(kls_rec)), kls_rec, label=\"kl_rec\")\n",
    "#         ax.plot(np.arange(len(rec_errs)), rec_errs, label=\"rec_err\")\n",
    "#         ax.set_ylim([0, 200])\n",
    "#         ax.legend()\n",
    "#         plt.savefig('./soft_intro_vae_train_graphs.jpg')\n",
    "#         # save models\n",
    "#         prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "#         save_checkpoint(model, epoch, cur_iter, prefix)\n",
    "#         plt.show()\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a833464-fbaf-4e16-aff2-54f0f737dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "num_epochs = 150\n",
    "lr = 2e-4\n",
    "batch_size = 16\n",
    "beta_kl = 1.0\n",
    "beta_rec = 1.0\n",
    "beta_neg = 256\n",
    "\n",
    "model = train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=batch_size, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                                 num_epochs=num_epochs, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                                 beta_kl=beta_kl, beta_rec=beta_rec, beta_neg=beta_neg, test_iter=1000, seed=-1, pretrained=None,\n",
    "                                 device=device)\n",
    "# train soft intro vae の引数の中にpretrainedがあるが、指定すれば呼べる？？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c215-7515-4bc8-bde1-075d612240a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "print(\"Note that these results are for 150 epochs, usually more is needed.\")\n",
    "num_samples = 64\n",
    "with torch.no_grad():\n",
    "    noise_batch = torch.randn(size=(num_samples, model.zdim)).to(device)\n",
    "    images = model.sample(noise_batch)\n",
    "    images = images.data.cpu().numpy()\n",
    "    images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    images = images / 255.0\n",
    "    images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "    grid = make_grid(images, nrow=8)\n",
    "    \n",
    "grid_np = grid.permute(1, 2, 0).data.cpu().numpy()   \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_generated.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee21f3f-05ed-4dcc-a38a-b6a6db62fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reconstructions\n",
    "# num_recon = 8\n",
    "# test_dataset = CIFAR10(root='./cifar10_ds', train=False, download=True, transform=transforms.ToTensor())\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=num_recon, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "# test_images = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3c967-de2e-46a6-bf44-76a32b142939",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    total_grid = []\n",
    "    for _ in range(3):\n",
    "        data = next(test_images)\n",
    "        recon = model(data[0].to(device), deterministic=True)[3]\n",
    "        images = recon.data.cpu().numpy()\n",
    "        images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "        images = images / 255.0\n",
    "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "        grid = make_grid(torch.cat([data[0], images], dim=0), nrow=8)\n",
    "        total_grid.append(grid)\n",
    "    \n",
    "total_grid = torch.cat(total_grid, dim=1)\n",
    "grid_np = total_grid.permute(1, 2, 0).data.cpu().numpy()  \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_reconstructions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8907a-3008-4331-8ac1-98a8a331db7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8bd17-d77c-46a9-b0bb-edb46a5d94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8966a1-c4f9-4e36-92ad-5791d374e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
