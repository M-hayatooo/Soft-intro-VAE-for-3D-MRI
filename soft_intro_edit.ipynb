{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438abb3-7f9a-4c4c-92a9-e64527ebcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import models.models as models\n",
    "import utils.confusion as confusion\n",
    "import utils.my_trainer as trainer\n",
    "import utils.train_result as train_result\n",
    "from datasets.dataset import load_data\n",
    "from utils.data_class import BrainDataset\n",
    "\n",
    "# import os.path as osp\n",
    "import torchio as tio\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from torchio.transforms.augmentation.intensity.random_bias_field import RandomBiasField\n",
    "from torchio.transforms.augmentation.intensity.random_noise import RandomNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8d10d4-2eae-4c48-8701-0b5a17688954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True #この行をFalseにすると再現性はとれるが、速度が落ちる\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return\n",
    "fix_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ac9304-9a2d-4025-9769-a2c150f00c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\"CN\": 0, \"AD\": 1}\n",
    "SEED_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4e817a-4014-45db-993d-f68de351b799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "data = load_data(kinds=[\"ADNI2\"], classes=[\"CN\"], unique=False, blacklist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20bcf3d-6f50-4ad1-8609-a1d09de8822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 346.35it/s]\n"
     ]
    }
   ],
   "source": [
    "pids = []\n",
    "voxels = np.zeros((len(data), 80, 96, 80))\n",
    "labels = np.zeros(len(data))\n",
    "for i in tqdm(range(len(data))):\n",
    "    pids.append(data[i][\"pid\"])\n",
    "    voxels[i] = data[i][\"voxel\"]\n",
    "    labels[i] = CLASS_MAP[data[i][\"label\"]]\n",
    "pids = np.array(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfe1bef-13a2-4acf-9cc9-14bfcb91136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import CLASS_MAP\n",
    "from torch.utils.data import Dataset\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, voxels, labels, transform=None):\n",
    "        self.voxels = voxels\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.voxels)\n",
    "    def __getitem__(self, index):\n",
    "        voxel = self.voxels[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            voxel = self.transform(voxel, self.phase)\n",
    "        voxel = self._preprocess(voxel)\n",
    "        return voxel, label\n",
    "    def _preprocess(self, voxel):\n",
    "        cut_range = 4\n",
    "        voxel = np.clip(voxel, 0, cut_range * np.std(voxel))\n",
    "        voxel = normalize(voxel, np.min(voxel), np.max(voxel))\n",
    "        voxel = voxel[np.newaxis, ]\n",
    "        return voxel.astype('f')\n",
    "    def __call__(self, index):\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    \n",
    "def normalize(voxel: np.ndarray, floor: int, ceil: int) -> np.ndarray:\n",
    "    return (voxel - floor) / (ceil - floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51db581-d3bc-46d7-941f-43f461c2f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "tid, vid = list(gss.split(voxels, groups=pids))[0]\n",
    "train_voxels = voxels[tid]\n",
    "val_voxels = voxels[vid]\n",
    "train_labels = labels[tid]\n",
    "val_labels = labels[vid]\n",
    "\n",
    "train_dataset = BrainDataset(train_voxels, train_labels)\n",
    "val_dataset = BrainDataset(val_voxels, val_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, num_workers=os.cpu_count(), pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8963cce0-f8c3-4427-ac93-b50696987aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2 ** 32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "# g = torch.Generator()\n",
    "# g.manual_seed(0)\n",
    "\n",
    "# num_workers = 2\n",
    "# batch_size = 16\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=seed_worker, generator=g)\n",
    "# val_dataloader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16bbef25-4291-4b17-8bae-f9072150bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_kl(logvar, mu, mu_o=0.0, logvar_o=0.0, reduce='sum'):\n",
    "    if not isinstance(mu_o, torch.Tensor):\n",
    "        mu_o = torch.tensor(mu_o).to(mu.device)\n",
    "    if not isinstance(logvar_o, torch.Tensor):\n",
    "        logvar_o = torch.tensor(logvar_o).to(mu.device)\n",
    "    kl = -0.5 * (1 + logvar - logvar_o - logvar.exp() / torch.exp(logvar_o) - (mu - mu_o).pow(2) / torch.exp(\n",
    "        logvar_o)).sum(1)\n",
    "    if reduce == 'sum':\n",
    "        kl = torch.sum(kl)\n",
    "    elif reduce == 'mean':\n",
    "        kl = torch.mean(kl)\n",
    "    return kl\n",
    "\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    \"\"\"\n",
    "    This function applies the reparameterization trick:\n",
    "    z = mu(X) + sigma(X)^0.5 * epsilon, where epsilon ~ N(0,I)\n",
    "    :param mu: mean of x\n",
    "    :param logvar: log variaance of x\n",
    "    :return z: the sampled latent variable\n",
    "    \"\"\"\n",
    "    device = mu.device\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std).to(device)\n",
    "    return mu + eps * std\n",
    "\n",
    "\n",
    "def calc_reconstruction_loss(x, recon_x, loss_type='mse', reduction='mean'):\n",
    "    x = x.view(x.size(0), -1)\n",
    "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    \n",
    "    recon_error = F.mse_loss(recon_x, x, reduction='none')\n",
    "    recon_error = recon_error.sum(1)\n",
    "    recon_error = recon_error.mean()\n",
    "    return recon_error\n",
    "\n",
    "\n",
    "def load_model(model, pretrained, device):\n",
    "    weights = torch.load(pretrained, map_location=device)\n",
    "    model.load_state_dict(weights['model'], strict=False)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, epoch, iteration, prefix=\"\"):\n",
    "    model_out_path = \"./saves/\" + prefix + \"model_epoch_{}_iter_{}.pth\".format(epoch, iteration)\n",
    "    state = {\"epoch\": epoch, \"model\": model.state_dict()}\n",
    "    if not os.path.exists(\"./saves/\"):\n",
    "        os.makedirs(\"./saves/\")\n",
    "\n",
    "    torch.save(state, model_out_path)\n",
    "\n",
    "    print(\"model checkpoint saved @ {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb03b5a-217e-4434-89ab-197b3b0f4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BuildingBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(BuildingBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool3d(kernel_size=stride),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "class UpsampleBuildingkBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, bias=False):\n",
    "        super(UpsampleBuildingkBlock, self).__init__()\n",
    "        self.res = stride == 1\n",
    "        self.shortcut = self._shortcut()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, in_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=stride),\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self):\n",
    "        return lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.res:\n",
    "            shortcut = self.shortcut(x)\n",
    "            return self.relu(self.block(x) + shortcut)\n",
    "        else:\n",
    "            return self.relu(self.block(x))\n",
    "\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.block_setting = block_setting\n",
    "        self.in_ch = in_ch\n",
    "        last = 1\n",
    "        blocks = [nn.Sequential(\n",
    "            nn.Conv3d(1, in_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm3d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )]\n",
    "        for line in self.block_setting:\n",
    "            c, n, s = line[0], line[1], line[2]\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(nn.Sequential(BuildingBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        self.inner_ch = in_ch\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.conv = nn.Conv3d(in_ch, last, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.blocks(x)\n",
    "        return self.conv(h)\n",
    "\n",
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, encoder: ResNetEncoder, blocks=None):\n",
    "        super(ResNetDecoder, self).__init__()\n",
    "        last = encoder.block_setting[-1][0]\n",
    "        if blocks is None:\n",
    "            blocks = [nn.Sequential(\n",
    "                nn.Conv3d(1, last, 1, 1, bias=True),\n",
    "                nn.BatchNorm3d(last),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )]\n",
    "        in_ch = last\n",
    "        for i in range(len(encoder.block_setting)):\n",
    "            if i == len(encoder.block_setting) - 1:\n",
    "                nc = encoder.in_ch\n",
    "            else:\n",
    "                nc = encoder.block_setting[::-1][i + 1][0]\n",
    "            c, n, s = encoder.block_setting[::-1][i]\n",
    "            for j in range(n):\n",
    "                stride = s if j == n - 1 else 1\n",
    "                c = nc if j == n - 1 else c\n",
    "                blocks.append(nn.Sequential(UpsampleBuildingkBlock(in_ch, c, stride)))\n",
    "                in_ch = c\n",
    "        blocks.append(nn.Sequential(\n",
    "            nn.Conv3d(in_ch, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.blocks(x)\n",
    "\n",
    "\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseEncoder, self).__init__()\n",
    "class BaseDecoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseDecoder, self).__init__()\n",
    "\n",
    "class BaseCAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseCAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "    def decode(self, z):\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        out = self.decode(z)\n",
    "        return out, z\n",
    "\n",
    "class BaseVAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaseVAE, self).__init__()\n",
    "        self.encoder = BaseEncoder()\n",
    "        self.decoder = BaseDecoder()\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "    def decode(self, vec):\n",
    "        out = self.decoder(vec)\n",
    "        return out\n",
    "    def reparameterize(self, mu, logvar) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        vec = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(vec)\n",
    "        return x_hat, vec, mu, logvar\n",
    "\n",
    "\n",
    "class ResNetCAE(BaseCAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetCAE, self).__init__()\n",
    "        self.encoder = ResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class VAEResNetEncoder(ResNetEncoder):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(VAEResNetEncoder, self).__init__(in_ch, block_setting)\n",
    "        self.mu = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "        self.var = nn.Conv3d(self.inner_ch, 1, kernel_size=1, stride=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h = self.blocks(x)\n",
    "        mu = self.mu(h)\n",
    "        var = self.var(h)\n",
    "        return mu, var\n",
    "\n",
    "\n",
    "class ResNetVAE(BaseVAE):\n",
    "    def __init__(self, in_ch, block_setting) -> None:\n",
    "        super(ResNetVAE, self).__init__()\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "\n",
    "    def reparamenterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparamenterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return x_re, mu, logvar\n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e869defe-1f68-4454-80ab-3003dfcc782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftIntroVAE(nn.Module):\n",
    "    def __init__(self, in_ch, block_setting, zdim=150, conditional=False):\n",
    "        super(SoftIntroVAE, self).__init__()\n",
    "        self.zdim = zdim\n",
    "        self.conditional = conditional\n",
    "        self.encoder = VAEResNetEncoder(\n",
    "            in_ch=in_ch,\n",
    "            block_setting=block_setting,\n",
    "        )\n",
    "        self.decoder = ResNetDecoder(self.encoder)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_re = self.decoder(z)\n",
    "        return mu, logvar, z, x_re\n",
    "    \n",
    "#     ↑ここの forward では  RETURN {{ mu, logvar, z, y }}を返したい (soft-intro-vae-tutorial-codeでは)    \n",
    "\n",
    "#    def Rmse(x_re, x):\n",
    "#        return torch.sqrt(torch.mean((x_re - x)**2))\n",
    "#    def ELBO(self, x_re, x, mu, logvar):\n",
    "#        re_err = self.Rmse(x_re, x)\n",
    "#        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "#        return re_err + kld\n",
    "\n",
    "    def loss(self, x_re, x, mu, logvar):\n",
    "        re_err = torch.sqrt(torch.mean((x_re - x)**2)) # ==  self.Rmse(x_re, x)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        return re_err + kld        \n",
    "            \n",
    "    def sample(self, z, y_cond=None):\n",
    "        # x.view(-1, 2) \n",
    "        z = z.view(32, 1, 5, 6, 5)# batchsize, channel, 5×6×5 (150)\n",
    "        y = self.decode(z, y_cond=y_cond)\n",
    "        return y\n",
    "\n",
    "    def sample_with_noise(self, num_samples=1, device=torch.device(\"cpu\"), y_cond=None):\n",
    "        z = torch.randn(num_samples, self.z_dim).to(device)\n",
    "        return self.decode(z, y_cond=y_cond)\n",
    "\n",
    "    def encode(self, x, o_cond=None):\n",
    "        # if self.conditional and o_cond is not None:\n",
    "        #     mu, logvar = self.encoder(x, o_cond=o_cond) # VAEResNetENcoder ⇒　return  mu, logvar\n",
    "        # else:\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z, y_cond=None):\n",
    "        # if self.conditional and y_cond is not None:\n",
    "        #     y = self.decoder(z, y_cond=y_cond)\n",
    "        # else:\n",
    "        y = self.decoder(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c360a2c0-a3f8-496a-9867-be9fa9f476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=16, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                           num_epochs=250, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                           beta_kl=1.0, beta_rec=1.0, beta_neg=1.0, test_iter=1000, seed=-1, pretrained=None,\n",
    "                           device=torch.device(\"cpu\"), num_row=8, gamma_r=1e-8):\n",
    "    if seed != -1:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        print(\"random seed: \", seed)\n",
    "\n",
    "    \n",
    "    model = SoftIntroVAE(12, [ [12,1,2],[24,1,2],[32,2,2],[48,2,2] ], conditional=False)\n",
    "    #model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "    model.to(device)\n",
    "    # もしpretrainedが存在しているのならば model param load\n",
    "    if pretrained is not None: \n",
    "        load_model(model, pretrained, device)\n",
    "    print(model)\n",
    "\n",
    "    optimizer_e = optim.Adam(model.encoder.parameters(), lr=lr_e)\n",
    "    optimizer_d = optim.Adam(model.decoder.parameters(), lr=lr_d)\n",
    "\n",
    "    e_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_e, milestones=(350,), gamma=0.1)\n",
    "    d_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=(350,), gamma=0.1)\n",
    "\n",
    "    scale = 1 / (80 * 96 * 80)  # normalizing constant, 's' in the paper  desu\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
    "#   train_data_loader = load_data(kinds=[\"ADNI2\",\"ADNI2-2\"], classes=[\"CN\", \"AD\"], unique=False, blacklist=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    cur_iter = 0\n",
    "    kls_real = []\n",
    "    kls_fake = []\n",
    "    kls_rec = []\n",
    "    rec_errs = []\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        diff_kls = []\n",
    "        # save models\n",
    "        if epoch % save_interval == 0 and epoch > 0:\n",
    "            save_epoch = (epoch // save_interval) * save_interval\n",
    "            prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "            save_checkpoint(model, save_epoch, cur_iter, prefix)\n",
    "\n",
    "        model.train()\n",
    "        batch_kls_real = []\n",
    "        batch_kls_fake = []\n",
    "        batch_kls_rec = []\n",
    "        batch_rec_errs = []\n",
    "\n",
    "#        for iteration, batch in enumerate(train_data_loader, 0):\n",
    "        for iteration, (batch, labels) in enumerate(train_data_loader, 0):# iterationには 自動で割り振られたindex番号が適用される\n",
    "#        for batch, labels in train_data_loader:# iterationには 自動で割り振られたindex番号が適用される\n",
    "        # enmuerate の第２引数はindexの開始番号の指定\n",
    "        # --------------train------------\n",
    "            b_size = batch.size(0)\n",
    "\n",
    "            noise_batch = torch.randn(size=(b_size, 1, 5, 6, 5)).to(device)\n",
    "            real_batch = batch.to(device)\n",
    "\n",
    "            # =========== Update E ================\n",
    "        #   fake = model.sample(noise_batch)\n",
    "            fake = model.decode(noise_batch)\n",
    "\n",
    "            real_mu, real_logvar = model.encode(real_batch)\n",
    "            z = model.reparameterize(real_mu, real_logvar)\n",
    "            rec = model.decode(z)\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            lossE_real_kl = calc_kl(real_logvar, real_mu, reduce=\"mean\")\n",
    "            # {{ mu,    logvar,    z   ,    y }}を返す\n",
    "            rec_mu, rec_logvar, z_rec, rec_rec     = model( rec.detach())\n",
    "            fake_mu, fake_logvar, z_fake, rec_fake = model(fake.detach())\n",
    "\n",
    "            fake_kl_e = calc_kl(fake_logvar, fake_mu, reduce=\"none\")\n",
    "            rec_kl_e = calc_kl(rec_logvar, rec_mu, reduce=\"none\")\n",
    "            \n",
    "            print(\"fake：\")\n",
    "            print( fake.size() )\n",
    "            print(\"rec_fake：\")\n",
    "            print( rec_fake.size() )            \n",
    "\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake, rec_fake, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec, rec_rec, loss_type=recon_loss_type, reduction=\"none\")\n",
    "            # loss fake rec がおかしい？\n",
    "            print(\"loss_fake_rec：\")\n",
    "            print( loss_fake_rec )\n",
    "            print(\" fake_kl_e：\" )\n",
    "            print(fake_kl_e)\n",
    "\n",
    "            exp_elbo_fake = (-2 * scale * (beta_rec * loss_fake_rec + beta_neg * fake_kl_e)).exp().mean()\n",
    "            exp_elbo_rec = (-2 * scale * (beta_rec * loss_rec_rec + beta_neg * rec_kl_e)).exp().mean()\n",
    "            # total loss\n",
    "            lossE = scale * (beta_rec * loss_rec + beta_kl * lossE_real_kl) + 0.25 * (exp_elbo_fake + exp_elbo_rec)\n",
    "            # backprop\n",
    "            optimizer_e.zero_grad()\n",
    "            lossE.backward()\n",
    "            optimizer_e.step()\n",
    "            print(\"finish updateE\")\n",
    "            # ========= Update D ==================\n",
    "            for param in model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.decoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            fake = model.decode(noise_batch)# \n",
    "            rec = model.decode(z.detach())\n",
    "\n",
    "            loss_rec = calc_reconstruction_loss(real_batch, rec.detach(),loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_mu, rec_logvar = model.encode(rec)\n",
    "            z_rec = reparameterize(rec_mu, rec_logvar)\n",
    "\n",
    "            fake_mu, fake_logvar = model.encode(fake)\n",
    "            z_fake = reparameterize(fake_mu, fake_logvar)\n",
    "\n",
    "            # rec_rec = model.decode(z_rec.detach())\n",
    "            # rec_fake = model.decode(z_fake.detach())\n",
    "            rec_rec = model.decode(z_rec)\n",
    "            rec_fake = model.decode(z_fake)\n",
    "\n",
    "            loss_rec_rec = calc_reconstruction_loss(rec.detach(), rec_rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "            loss_fake_rec = calc_reconstruction_loss(fake.detach(), rec_fake, loss_type=recon_loss_type, reduction=\"mean\")\n",
    "\n",
    "            rec_kl = calc_kl(rec_logvar, rec_mu, reduce=\"mean\")\n",
    "            fake_kl = calc_kl(fake_logvar, fake_mu, reduce=\"mean\")\n",
    "\n",
    "            lossD = scale * (loss_rec * beta_rec + (rec_kl + fake_kl) * 0.5 * beta_kl + \\\n",
    "                                         gamma_r * 0.5 * beta_rec * (loss_rec_rec + loss_fake_rec))\n",
    "\n",
    "            optimizer_d.zero_grad()\n",
    "            lossD.backward()\n",
    "            optimizer_d.step()\n",
    "            print(\"finish updateD\")\n",
    "\n",
    "            if torch.isnan(lossD) or torch.isnan(lossE):\n",
    "                raise SystemError\n",
    "\n",
    "            # statistics for plotting later\n",
    "            diff_kls.append(-lossE_real_kl.data.cpu().item() + fake_kl.data.cpu().item())\n",
    "            batch_kls_real.append(lossE_real_kl.data.cpu().item())\n",
    "            batch_kls_fake.append(fake_kl.cpu().item())\n",
    "            batch_kls_rec.append(rec_kl.data.cpu().item())\n",
    "            batch_rec_errs.append(loss_rec.data.cpu().item())\n",
    "\n",
    "            if cur_iter % test_iter == 0:\n",
    "                info = \"\\nEpoch[{}]({}/{}): time: {:4.4f}: \".format(epoch, iteration, len(train_data_loader), time.time() - start_time)\n",
    "                info += 'Rec: {:.4f}, '.format(loss_rec.data.cpu())\n",
    "                info += 'Kl_E: {:.4f}, expELBO_R: {:.4e}, expELBO_F: {:.4e}, '.format(lossE_real_kl.data.cpu(),\n",
    "                                                                                exp_elbo_rec.data.cpu(),\n",
    "                                                                                exp_elbo_fake.cpu())\n",
    "                info += 'Kl_F: {:.4f}, KL_R: {:.4f}'.format(rec_kl.data.cpu(), fake_kl.data.cpu())\n",
    "                info += ' DIFF_Kl_F: {:.4f}'.format(-lossE_real_kl.data.cpu() + fake_kl.data.cpu())\n",
    "                print(info)\n",
    "\n",
    "                _, _, _, rec_det = model(real_batch)\n",
    "                max_imgs = min(batch.size(0), 16)\n",
    "                # vutils.save_image(\n",
    "                #         torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "                #         '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)                 \n",
    "        cur_iter += 1\n",
    "    e_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "\n",
    "    if epoch > num_vae - 1:\n",
    "        kls_real.append(np.mean(batch_kls_real))\n",
    "        kls_fake.append(np.mean(batch_kls_fake))\n",
    "        kls_rec.append(np.mean(batch_kls_rec))\n",
    "        rec_errs.append(np.mean(batch_rec_errs))\n",
    "\n",
    "#     if epoch == num_epochs - 1:\n",
    "#         with torch.no_grad():\n",
    "#             _, _, _, rec_det = model(real_batch)\n",
    "#             noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
    "#             fake = model.sample(noise_batch)\n",
    "#             max_imgs = min(batch.size(0), 16)\n",
    "#             vutils.save_image(\n",
    "#                     torch.cat([real_batch[:max_imgs], rec_det[:max_imgs], fake[:max_imgs]], dim=0).data.cpu(),\n",
    "#                     '{}/image_{}.jpg'.format(\"./\", cur_iter), nrow=num_row)\n",
    "\n",
    "#         # plot graphs\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(1, 1, 1)\n",
    "#         ax.plot(np.arange(len(kls_real)), kls_real, label=\"kl_real\")\n",
    "#         ax.plot(np.arange(len(kls_fake)), kls_fake, label=\"kl_fake\")\n",
    "#         ax.plot(np.arange(len(kls_rec)), kls_rec, label=\"kl_rec\")\n",
    "#         ax.plot(np.arange(len(rec_errs)), rec_errs, label=\"rec_err\")\n",
    "#         ax.set_ylim([0, 200])\n",
    "#         ax.legend()\n",
    "#         plt.savefig('./soft_intro_vae_train_graphs.jpg')\n",
    "#         # save models\n",
    "#         prefix = dataset + \"_soft_intro_vae\" + \"_betas_\" + str(beta_kl) + \"_\" + str(beta_neg) + \"_\" + str(beta_rec) + \"_\"\n",
    "#         save_checkpoint(model, epoch, cur_iter, prefix)\n",
    "#         plt.show()\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a833464-fbaf-4e16-aff2-54f0f737dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "SoftIntroVAE(\n",
      "  (encoder): VAEResNetEncoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(24, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BuildingBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): AvgPool3d(kernel_size=1, stride=1, padding=0)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    (mu): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    (var): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (decoder): ResNetDecoder(\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv3d(1, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=1.0, mode=nearest)\n",
      "            (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=1.0, mode=nearest)\n",
      "            (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(32, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): UpsampleBuildingkBlock(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (block): Sequential(\n",
      "            (0): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "            (4): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            (5): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Conv3d(12, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "fake：\n",
      "torch.Size([16, 1, 80, 96, 80])\n",
      "rec_fake：\n",
      "torch.Size([16, 1, 80, 96, 80])\n",
      "loss_fake_rec：\n",
      "tensor(87107.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      " fake_kl_e：\n",
      "tensor([[[[1.1436e-01, 2.3606e-01, 5.7838e-03, 1.8831e-02, 5.1289e-02],\n",
      "          [7.4033e-02, 1.3428e+00, 6.2898e-01, 5.5933e-01, 1.7891e-01],\n",
      "          [1.2586e-01, 1.4582e-01, 1.2831e-01, 6.4267e-01, 1.9219e-02],\n",
      "          [7.5765e-02, 1.1077e+00, 5.2676e-02, 9.7761e-01, 3.1815e-01],\n",
      "          [1.2247e-02, 1.3051e-01, 1.5217e-01, 3.6473e-01, 7.5766e-02],\n",
      "          [1.6702e-01, 2.8535e-01, 7.8892e-02, 4.1301e-01, 3.3837e-01]],\n",
      "\n",
      "         [[1.5822e-01, 1.3257e-01, 2.7159e-01, 1.3841e-01, 3.9960e-01],\n",
      "          [2.7890e-01, 4.1548e-01, 4.6885e-01, 1.5333e-01, 1.6664e-01],\n",
      "          [2.8877e-02, 3.4684e+00, 1.6802e-01, 7.0114e-01, 6.4973e-01],\n",
      "          [1.6827e-01, 1.5998e+00, 2.0740e+00, 6.6453e-01, 2.2567e-01],\n",
      "          [1.7523e-01, 6.4964e-01, 2.8504e-01, 1.2222e+00, 1.0855e+00],\n",
      "          [5.0735e-01, 6.4056e-01, 9.4903e-01, 4.9666e-01, 1.1043e-01]],\n",
      "\n",
      "         [[5.8373e-01, 2.1867e-01, 2.3015e-01, 2.1684e-01, 2.7485e-01],\n",
      "          [1.0917e+00, 1.1314e+00, 4.6753e-01, 9.2222e-01, 1.1935e-01],\n",
      "          [1.2652e+00, 4.4125e+00, 2.2741e-01, 1.0403e+00, 8.0457e-02],\n",
      "          [3.0352e-01, 4.7716e+00, 3.3472e-01, 5.7441e-01, 5.5966e-01],\n",
      "          [4.9180e-01, 1.7047e+00, 5.3730e-01, 8.6420e-01, 5.8576e-01],\n",
      "          [3.4652e-01, 2.1859e-01, 3.5790e-01, 4.4009e-01, 8.7983e-01]],\n",
      "\n",
      "         [[2.6982e-01, 2.0938e-01, 4.3031e-01, 8.3308e-01, 3.1527e-01],\n",
      "          [4.2257e-01, 6.0593e-01, 3.9052e-01, 7.2165e-01, 1.1399e-01],\n",
      "          [2.0195e+00, 8.5657e-01, 1.3536e+00, 2.4488e-01, 1.6941e-01],\n",
      "          [1.0891e+00, 1.4391e+00, 1.9664e+00, 2.0991e+00, 8.1053e-01],\n",
      "          [1.6022e+00, 5.3946e+00, 2.3104e+00, 1.1540e+00, 2.2171e+00],\n",
      "          [6.2732e-01, 5.9348e-01, 6.4573e-01, 1.7488e-02, 2.1866e-01]],\n",
      "\n",
      "         [[4.6620e-01, 4.8926e-01, 3.3329e-01, 6.7996e-01, 4.5928e-01],\n",
      "          [5.9207e-01, 1.7981e+00, 1.9617e+00, 1.3892e+00, 2.4978e-01],\n",
      "          [5.8079e-01, 2.2474e+00, 1.2963e+00, 9.7526e-01, 5.1763e-01],\n",
      "          [9.5018e-01, 8.4560e-01, 1.1798e+00, 1.1862e+00, 8.9375e-01],\n",
      "          [7.8848e-01, 2.7116e+00, 8.1703e-01, 2.9414e+00, 1.0017e+00],\n",
      "          [7.1414e-01, 6.8180e-01, 1.6629e+00, 1.7251e+00, 6.9088e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.5463e-01, 1.0746e-02, 6.6976e-02, 2.6357e-01, 1.1227e-02],\n",
      "          [4.4937e-01, 9.3989e-02, 9.4655e-02, 3.2276e-01, 2.6144e-01],\n",
      "          [2.3033e-01, 1.4019e-01, 3.9692e-02, 3.1809e-01, 6.3459e-01],\n",
      "          [9.6077e-02, 1.4873e-01, 1.5863e-02, 6.3457e-01, 4.6926e-01],\n",
      "          [1.9686e-01, 1.7105e-01, 5.1140e-03, 1.9187e-01, 1.3784e-01],\n",
      "          [1.1489e-01, 1.7302e-01, 3.4269e-01, 3.1373e-01, 6.1846e-01]],\n",
      "\n",
      "         [[1.1307e-01, 9.8520e-02, 9.0312e-02, 2.5949e-01, 5.3450e-02],\n",
      "          [4.9859e-01, 5.5901e-01, 1.4804e-01, 6.7971e-01, 2.8026e-01],\n",
      "          [2.9961e-02, 6.3415e-01, 4.2817e-01, 9.5414e-01, 3.8344e-01],\n",
      "          [2.7009e-01, 6.1247e-01, 3.7202e-01, 5.1806e-01, 3.1154e-01],\n",
      "          [1.0444e-01, 9.9582e-01, 4.9691e-01, 4.2746e-01, 4.6003e-01],\n",
      "          [2.7738e-01, 8.2214e-01, 4.0637e-01, 1.4582e-01, 3.6120e-01]],\n",
      "\n",
      "         [[4.1040e-02, 3.2376e-01, 3.1232e-01, 6.1065e-02, 1.4495e-01],\n",
      "          [7.1717e-01, 1.8754e+00, 1.8435e-01, 2.6967e-01, 6.8365e-01],\n",
      "          [2.6234e-01, 1.3262e+00, 6.2433e-01, 6.0241e-01, 7.4293e-02],\n",
      "          [6.9420e-02, 1.9676e+00, 9.6072e-01, 3.0854e-01, 5.0770e-01],\n",
      "          [2.4383e-01, 5.9935e-01, 2.8615e-01, 2.2379e+00, 3.7224e-01],\n",
      "          [8.6082e-02, 3.5008e-01, 1.2917e-01, 1.5718e-01, 1.4443e-01]],\n",
      "\n",
      "         [[5.4715e-02, 2.2772e-01, 4.2523e-01, 5.4378e-01, 4.0366e-01],\n",
      "          [1.9042e-01, 5.4228e-01, 1.1691e-01, 4.4359e-01, 5.1296e-02],\n",
      "          [8.3869e-01, 1.7984e+00, 8.4619e-01, 1.1182e+00, 2.5828e-01],\n",
      "          [2.8449e-01, 3.1404e-01, 1.0752e+00, 2.0172e+00, 2.1655e-01],\n",
      "          [6.2790e-01, 1.0784e+00, 1.3775e+00, 2.5110e+00, 4.4044e-01],\n",
      "          [5.7683e-01, 2.2159e-01, 5.1098e-01, 3.5920e-01, 3.1935e-01]],\n",
      "\n",
      "         [[3.7041e-01, 6.2575e-01, 5.6001e-01, 1.0124e+00, 5.6800e-01],\n",
      "          [4.9913e-01, 1.1612e+00, 4.4222e-01, 9.1863e-01, 3.6106e-01],\n",
      "          [9.1911e-01, 1.0460e+00, 3.2365e-01, 7.2347e-01, 1.7836e+00],\n",
      "          [7.0134e-01, 2.6620e+00, 3.0623e-01, 2.4696e+00, 6.5740e-01],\n",
      "          [1.0450e+00, 3.9344e+00, 3.4449e+00, 2.7121e+00, 7.5630e-01],\n",
      "          [8.1559e-01, 1.3772e+00, 4.6635e-01, 6.3489e-01, 4.8084e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.4308e-01, 3.6423e-02, 8.4021e-02, 4.6673e-02, 2.9789e-02],\n",
      "          [2.9144e-01, 1.9538e-01, 3.1936e-01, 2.5279e-01, 3.4814e-01],\n",
      "          [2.5137e-01, 1.7608e-01, 2.4857e-01, 2.1557e-01, 9.8046e-02],\n",
      "          [5.4521e-02, 8.0610e-02, 2.8108e-01, 2.2013e-01, 9.2510e-01],\n",
      "          [6.1458e-02, 3.1835e-01, 1.8089e-01, 3.7799e-01, 3.1474e-01],\n",
      "          [2.5688e-01, 4.1563e-01, 3.9300e-01, 7.9587e-02, 6.1484e-01]],\n",
      "\n",
      "         [[3.0066e-01, 1.4817e-01, 7.8003e-02, 3.6030e-01, 1.4466e-01],\n",
      "          [3.3798e-01, 8.7740e-01, 4.1411e-01, 7.7026e-01, 1.5052e-01],\n",
      "          [2.1007e-01, 3.9008e-02, 1.6904e-01, 2.0361e+00, 1.7458e-01],\n",
      "          [7.2736e-02, 8.4901e-01, 2.9201e-01, 1.1275e+00, 4.8871e-01],\n",
      "          [2.2819e-01, 2.4589e-01, 4.0202e-01, 1.1654e+00, 2.9769e-02],\n",
      "          [2.4859e-01, 3.4084e-01, 5.5441e-02, 2.8348e-01, 2.2538e-01]],\n",
      "\n",
      "         [[1.3911e-01, 2.7720e-01, 1.2445e+00, 3.4053e-01, 3.0423e-02],\n",
      "          [3.5087e-01, 1.7701e+00, 5.3844e-01, 7.9176e-01, 8.1596e-01],\n",
      "          [8.9815e-01, 1.3108e+00, 5.6653e-01, 4.1998e-01, 2.6100e-01],\n",
      "          [5.2455e-01, 3.8717e+00, 1.4635e+00, 5.2710e-01, 4.4105e-01],\n",
      "          [3.7757e-01, 8.6656e-01, 3.6713e-01, 2.2630e+00, 6.4878e-01],\n",
      "          [1.3546e-01, 7.1210e-01, 7.0592e-02, 3.4954e-01, 3.1290e-01]],\n",
      "\n",
      "         [[3.6242e-01, 1.2801e-01, 3.0136e-01, 1.0514e+00, 2.4641e-01],\n",
      "          [6.5573e-01, 4.7664e-01, 4.4301e-01, 1.0466e+00, 2.9104e-01],\n",
      "          [6.3030e-01, 1.2063e+00, 5.5304e-01, 8.7184e-01, 2.7958e-01],\n",
      "          [4.8042e-01, 3.8930e+00, 9.6810e-01, 8.8116e-01, 1.9321e-01],\n",
      "          [5.8214e-01, 1.0143e+00, 4.3296e-01, 8.8667e-01, 1.5405e-01],\n",
      "          [4.9527e-01, 5.1226e-01, 5.7074e-01, 5.4793e-01, 1.2887e-01]],\n",
      "\n",
      "         [[4.8033e-01, 5.6678e-01, 3.5433e-01, 2.1852e-01, 2.8025e-01],\n",
      "          [2.1133e-01, 6.9343e-01, 3.9804e-01, 1.9029e-01, 5.1745e-01],\n",
      "          [4.1820e-01, 1.1880e+00, 1.9078e-01, 9.3440e-01, 9.0452e-01],\n",
      "          [5.1571e-01, 8.0432e-01, 1.0405e-01, 1.0484e+00, 1.4170e-01],\n",
      "          [4.5216e-01, 1.2525e+00, 6.4194e-01, 1.0945e+00, 4.3637e-01],\n",
      "          [2.7932e-01, 2.8891e-01, 3.7915e-01, 3.4974e-01, 3.7947e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.3449e-01, 1.7783e-02, 3.4629e-01, 1.6172e-01, 8.8830e-02],\n",
      "          [1.3431e-01, 5.0844e-01, 3.9624e-01, 3.0506e-01, 2.9832e-01],\n",
      "          [1.2511e-01, 3.3418e-01, 2.4227e-01, 4.6448e-02, 3.0874e-01],\n",
      "          [6.2275e-02, 7.7024e-02, 5.2757e-02, 2.2609e-01, 4.2696e-01],\n",
      "          [1.7141e-01, 6.3846e-01, 7.1204e-02, 5.5303e-02, 3.6853e-02],\n",
      "          [2.0910e-01, 1.1358e-01, 7.8312e-02, 2.6860e-01, 4.3941e-01]],\n",
      "\n",
      "         [[5.5418e-02, 8.7633e-02, 4.2964e-01, 8.3101e-02, 3.5794e-01],\n",
      "          [2.5421e-01, 8.6556e-01, 7.5592e-01, 1.0235e+00, 4.4452e-01],\n",
      "          [2.2584e-01, 1.9297e-01, 5.2039e-01, 7.4716e-01, 2.9294e-01],\n",
      "          [2.5335e-01, 8.1770e-02, 7.7291e-01, 2.0699e+00, 2.8987e-01],\n",
      "          [2.4319e-01, 9.5433e-01, 3.9329e-01, 3.2255e-01, 7.6075e-02],\n",
      "          [2.9941e-01, 2.5225e-01, 6.4836e-02, 1.8159e-03, 1.1189e-02]],\n",
      "\n",
      "         [[7.1761e-02, 8.7393e-02, 2.2521e-01, 4.4605e-01, 1.5944e-01],\n",
      "          [4.7117e-01, 8.7555e-01, 3.6779e-01, 9.9361e-01, 2.7820e-01],\n",
      "          [6.3388e-01, 1.5779e+00, 9.5322e-01, 4.5313e-01, 5.4480e-01],\n",
      "          [5.7987e-01, 5.8651e-01, 1.2539e+00, 1.1258e+00, 3.4641e-01],\n",
      "          [4.0152e-01, 1.0716e+00, 2.0610e-01, 3.2606e-01, 1.6957e-01],\n",
      "          [1.4213e-01, 2.0423e-01, 9.9500e-02, 2.2957e-01, 1.7312e-01]],\n",
      "\n",
      "         [[7.6023e-02, 1.8837e-01, 2.0343e-01, 2.6465e-01, 2.0180e-01],\n",
      "          [1.5496e-01, 7.6481e-01, 1.4207e-01, 2.5707e-01, 1.9544e-01],\n",
      "          [7.8632e-01, 4.8879e-01, 4.7103e-01, 9.2311e-01, 4.2591e-02],\n",
      "          [3.0564e-01, 8.7845e-01, 5.2111e-01, 3.3584e-01, 7.2639e-02],\n",
      "          [1.4781e-01, 7.7976e-01, 3.4587e-01, 8.2988e-01, 1.5346e-01],\n",
      "          [2.7526e-01, 5.3994e-01, 3.6155e-01, 3.2818e-01, 2.4755e-01]],\n",
      "\n",
      "         [[2.2038e-01, 8.2004e-02, 1.0231e-01, 5.2445e-01, 2.1122e-01],\n",
      "          [1.6723e-01, 5.9641e-01, 5.0189e-01, 1.4358e-01, 3.2428e-01],\n",
      "          [2.7122e-01, 4.8821e-01, 4.5491e-01, 3.8336e-01, 2.1433e-01],\n",
      "          [3.0469e-01, 4.2810e-01, 3.7015e-01, 7.0388e-02, 2.2609e-01],\n",
      "          [9.8223e-02, 8.0762e-01, 5.6509e-01, 1.0368e+00, 2.1798e-01],\n",
      "          [1.9544e-01, 2.5270e-01, 1.4932e-01, 2.1848e-01, 4.5608e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.5339e-01, 8.3479e-02, 6.9242e-02, 1.6136e-01, 1.3782e-01],\n",
      "          [2.5995e-01, 3.2003e-01, 1.9256e-01, 2.6995e-01, 2.7799e-01],\n",
      "          [5.1212e-02, 2.2770e-01, 7.2007e-02, 5.0332e-01, 5.3695e-02],\n",
      "          [1.3291e-01, 1.1096e-01, 7.4284e-02, 2.3988e-02, 1.5018e-01],\n",
      "          [1.3679e-01, 1.4054e-01, 2.6911e-01, 1.8339e-02, 3.3072e-02],\n",
      "          [2.2890e-01, 3.0353e-01, 6.5065e-02, 2.4858e-01, 6.1051e-01]],\n",
      "\n",
      "         [[1.5508e-01, 1.2218e-01, 5.2766e-01, 1.2849e-01, 1.7202e-01],\n",
      "          [2.1756e-01, 1.3520e-01, 2.5716e-01, 6.4311e-01, 3.9362e-01],\n",
      "          [1.0160e-01, 4.5938e-01, 4.3799e-01, 5.1824e-01, 8.8188e-02],\n",
      "          [8.3433e-02, 4.9112e-01, 9.3565e-03, 3.1889e-01, 1.1870e-01],\n",
      "          [1.3896e-01, 2.5464e-01, 1.7081e-01, 4.4737e-01, 6.7360e-01],\n",
      "          [4.0079e-01, 1.7450e-01, 9.3443e-02, 1.5346e-01, 1.0923e-02]],\n",
      "\n",
      "         [[4.2733e-02, 3.9045e-01, 2.9867e-03, 1.1497e-01, 3.8962e-01],\n",
      "          [2.1483e-01, 1.7961e+00, 6.7046e-01, 6.3071e-01, 6.9408e-02],\n",
      "          [8.4393e-02, 1.7120e+00, 2.0542e-02, 2.8403e-01, 4.3521e-01],\n",
      "          [3.2929e-01, 3.4700e-01, 5.3818e-01, 9.2555e-01, 4.3235e-01],\n",
      "          [1.0366e-01, 6.8904e-01, 2.4146e-01, 1.1016e+00, 2.0830e-01],\n",
      "          [3.3971e-01, 2.4751e-01, 9.7086e-02, 2.2822e-01, 3.3050e-01]],\n",
      "\n",
      "         [[1.2525e-01, 1.9036e-01, 3.3913e-01, 3.1383e-01, 2.7070e-01],\n",
      "          [4.6495e-01, 2.3066e+00, 1.9373e+00, 6.5955e-01, 2.1993e-01],\n",
      "          [5.3902e-01, 7.6535e-01, 3.1544e-01, 1.4228e+00, 5.1332e-02],\n",
      "          [1.2993e+00, 1.5179e+00, 6.6242e-01, 3.0001e-01, 5.7843e-01],\n",
      "          [7.2443e-01, 1.8178e+00, 4.9239e-01, 2.0363e+00, 5.3816e-01],\n",
      "          [9.8137e-01, 2.1580e-01, 5.1407e-01, 2.8746e-01, 3.8266e-01]],\n",
      "\n",
      "         [[6.1157e-01, 3.7783e-01, 5.7822e-01, 3.1565e-01, 2.0142e-01],\n",
      "          [9.1027e-01, 2.3451e+00, 3.9176e+00, 1.4087e+00, 9.1929e-01],\n",
      "          [4.8141e-01, 1.3943e+00, 2.0288e+00, 7.6043e-01, 1.1303e+00],\n",
      "          [1.0303e+00, 2.9527e+00, 1.6724e+00, 5.6924e-01, 1.2500e+00],\n",
      "          [7.8881e-01, 5.2799e+00, 9.3940e-01, 1.4656e+00, 9.8454e-01],\n",
      "          [1.1078e+00, 1.2280e+00, 1.2617e+00, 4.9218e-01, 5.8838e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.1308e-01, 1.2035e-01, 1.0041e-02, 8.5238e-02, 2.7634e-02],\n",
      "          [1.1827e-02, 2.9694e-01, 1.9237e-01, 4.1559e-01, 1.2985e-01],\n",
      "          [2.3256e-01, 5.4598e-01, 3.5289e-01, 4.1919e-01, 4.6367e-02],\n",
      "          [2.0692e-01, 5.3033e-02, 1.9337e-01, 1.3633e+00, 1.1446e+00],\n",
      "          [1.8212e-02, 5.4836e-01, 7.5278e-01, 1.4550e+00, 2.2412e-01],\n",
      "          [3.7231e-01, 1.6162e-01, 2.0066e-02, 3.8472e-01, 2.4455e-01]],\n",
      "\n",
      "         [[4.2272e-01, 3.1906e-01, 1.7894e-01, 2.3456e-01, 1.7505e-01],\n",
      "          [2.6650e-01, 8.6393e-01, 4.9402e-01, 7.6184e-01, 1.2270e-01],\n",
      "          [3.1494e-01, 1.0474e-01, 2.4265e-01, 2.7062e+00, 2.1579e-01],\n",
      "          [2.4574e-01, 9.4159e-01, 2.1319e-01, 9.1351e-01, 1.5970e+00],\n",
      "          [4.5423e-01, 2.1589e+00, 6.8887e-01, 1.0234e+00, 3.8888e-01],\n",
      "          [2.5811e-01, 5.7875e-01, 1.9661e-01, 5.0336e-02, 1.1302e-01]],\n",
      "\n",
      "         [[2.7800e-01, 6.6049e-01, 4.7584e-01, 2.1983e-01, 2.5575e-01],\n",
      "          [5.8018e-01, 1.9201e+00, 7.8350e-01, 6.1996e-01, 1.2472e-01],\n",
      "          [7.8250e-01, 2.0145e+00, 4.3392e-01, 4.1737e-01, 3.9144e-01],\n",
      "          [1.1483e+00, 2.0965e+00, 3.0274e+00, 1.0342e+00, 2.6323e-01],\n",
      "          [8.5343e-01, 5.0104e+00, 7.4847e-01, 1.8868e+00, 1.0027e+00],\n",
      "          [2.0720e-01, 1.4090e+00, 1.3437e-01, 6.8577e-01, 2.5977e-01]],\n",
      "\n",
      "         [[3.4398e-01, 1.7555e-01, 3.5701e-01, 6.5773e-01, 2.2801e-01],\n",
      "          [6.5521e-01, 3.6685e-01, 2.2198e-01, 8.1180e-01, 1.9340e-01],\n",
      "          [1.4970e+00, 1.4300e+00, 1.5244e+00, 1.1103e+00, 3.1024e-01],\n",
      "          [9.2292e-01, 3.4069e+00, 2.5461e+00, 1.1513e+00, 4.9477e-01],\n",
      "          [8.1901e-01, 1.2857e+00, 6.3533e-01, 8.5625e-01, 1.7571e-01],\n",
      "          [4.3870e-01, 6.8869e-01, 4.3652e-01, 4.6146e-01, 1.4213e-01]],\n",
      "\n",
      "         [[2.3698e-01, 4.4418e-01, 4.2098e-01, 4.3852e-01, 3.4581e-01],\n",
      "          [2.3865e-01, 9.1913e-01, 5.8022e-01, 7.5448e-01, 4.3999e-01],\n",
      "          [6.5002e-01, 1.3714e+00, 1.7121e-01, 1.5383e+00, 1.1025e+00],\n",
      "          [4.8948e-01, 1.0732e+00, 4.8099e-01, 1.0046e+00, 2.0763e-01],\n",
      "          [1.8653e-01, 1.5836e+00, 6.7328e-01, 7.2577e-01, 4.4074e-01],\n",
      "          [4.2670e-01, 6.1729e-01, 2.9524e-01, 5.0002e-01, 3.3114e-01]]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "finish updateE\n",
      "finish updateD\n",
      "\n",
      "Epoch[0](0/8): time: 7.9658: Rec: 89968.5625, Kl_E: 0.8842, expELBO_R: 7.5698e-01, expELBO_F: 7.5250e-01, Kl_F: 34.0698, KL_R: 112.8557 DIFF_Kl_F: 111.9715\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (96) must match the size of tensor b (80) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m beta_rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m      9\u001b[0m beta_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_soft_intro_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_e\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_vae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecon_loss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbeta_kl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_kl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_rec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_rec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_neg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_neg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mtrain_soft_intro_vae\u001b[0;34m(z_dim, lr_e, lr_d, batch_size, num_workers, start_epoch, num_epochs, num_vae, save_interval, recon_loss_type, beta_kl, beta_rec, beta_neg, test_iter, seed, pretrained, device, num_row, gamma_r)\u001b[0m\n\u001b[1;32m    160\u001b[0m             _, _, _, rec_det \u001b[38;5;241m=\u001b[39m model(real_batch)\n\u001b[1;32m    161\u001b[0m             max_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m             \u001b[43mvutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_imgs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrec_det\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_imgs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_imgs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/image_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_row\u001b[49m\u001b[43m)\u001b[49m                 \n\u001b[1;32m    165\u001b[0m     cur_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    166\u001b[0m e_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.8/envs/brain/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.8/envs/brain/lib/python3.8/site-packages/torchvision/utils.py:132\u001b[0m, in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_image\u001b[39m(\n\u001b[1;32m    115\u001b[0m     tensor: Union[torch\u001b[38;5;241m.\u001b[39mTensor, List[torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Save a given Tensor into an image file.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        **kwargs: Other arguments are documented in ``make_grid``.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     grid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     ndarr \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.8/envs/brain/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.8/envs/brain/lib/python3.8/site-packages/torchvision/utils.py:106\u001b[0m, in \u001b[0;36mmake_grid\u001b[0;34m(tensor, nrow, padding, normalize, value_range, scale_each, pad_value, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# Tensor.copy_() is a valid method but seems to be missing from the stubs\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# https://pytorch.org/docs/stable/tensors.html#torch.Tensor.copy_\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m         k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (96) must match the size of tensor b (80) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "num_epochs = 150\n",
    "lr = 2e-4\n",
    "batch_size = 16\n",
    "beta_kl = 1.0\n",
    "beta_rec = 1.0\n",
    "beta_neg = 256\n",
    "\n",
    "model = train_soft_intro_vae(z_dim=150, lr_e=2e-4, lr_d=2e-4, batch_size=batch_size, num_workers=os.cpu_count(), start_epoch=0,\n",
    "                                 num_epochs=num_epochs, num_vae=0, save_interval=5000, recon_loss_type=\"mse\",\n",
    "                                 beta_kl=beta_kl, beta_rec=beta_rec, beta_neg=beta_neg, test_iter=1000, seed=-1, pretrained=None,\n",
    "                                 device=device)\n",
    "# train soft intro vae の引数の中にpretrainedがあるが、指定すれば呼べる？？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c215-7515-4bc8-bde1-075d612240a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "print(\"Note that these results are for 150 epochs, usually more is needed.\")\n",
    "num_samples = 64\n",
    "with torch.no_grad():\n",
    "    noise_batch = torch.randn(size=(num_samples, model.zdim)).to(device)\n",
    "    images = model.sample(noise_batch)\n",
    "    images = images.data.cpu().numpy()\n",
    "    images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    images = images / 255.0\n",
    "    images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "    grid = make_grid(images, nrow=8)\n",
    "    \n",
    "grid_np = grid.permute(1, 2, 0).data.cpu().numpy()   \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_generated.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee21f3f-05ed-4dcc-a38a-b6a6db62fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reconstructions\n",
    "# num_recon = 8\n",
    "# test_dataset = CIFAR10(root='./cifar10_ds', train=False, download=True, transform=transforms.ToTensor())\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=num_recon, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "# test_images = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3c967-de2e-46a6-bf44-76a32b142939",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    total_grid = []\n",
    "    for _ in range(3):\n",
    "        data = next(test_images)\n",
    "        recon = model(data[0].to(device), deterministic=True)[3]\n",
    "        images = recon.data.cpu().numpy()\n",
    "        images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "        images = images / 255.0\n",
    "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "        grid = make_grid(torch.cat([data[0], images], dim=0), nrow=8)\n",
    "        total_grid.append(grid)\n",
    "    \n",
    "total_grid = torch.cat(total_grid, dim=1)\n",
    "grid_np = total_grid.permute(1, 2, 0).data.cpu().numpy()  \n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(grid_np)\n",
    "ax.set_axis_off()\n",
    "plt.savefig('cifa10_grid_reconstructions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8907a-3008-4331-8ac1-98a8a331db7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8bd17-d77c-46a9-b0bb-edb46a5d94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8966a1-c4f9-4e36-92ad-5791d374e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
